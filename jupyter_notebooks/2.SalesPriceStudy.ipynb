{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Sale Price Correlation Study**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "1. Answer business requirement 1:\n",
        "    * *The client is interested in discovering how the house attributes correlate with the sale price. Therefore, the client expects data visualizations of the correlated variables against the sale price to show that.*\n",
        "    * In this notebook, we will perform a correlation study and plot graphs to represent our findings\n",
        "\n",
        "\n",
        "2. Attempt to validate our hypotheses:\n",
        "    * As laid out in the corresponding REAME.md, our correltation sudy can be used to test our project hypotheses\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* inputs/datasets/unzipped/house_prices_records.csv \n",
        "\n",
        "## Outputs\n",
        "\n",
        "* In this notebook we will generate code and graphs to answer buiness requiremnt 1, test our hypotheses and use in our Streamlit App\n",
        "\n",
        "\n",
        "## CRISP-DM\n",
        "* Data Understanding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* The notebooks are stored in a sub folder, therefore when running the notebook in the editor, you will need to change the working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(f\"inputs/datasets/unzipped/house_prices_records.csv\")\n",
        "print(df.shape)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We will run a profile report in order to get a more detailed look at our data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pandas_profiling import ProfileReport\n",
        "\n",
        "pandas_report = ProfileReport(df=df, minimal=True)\n",
        "pandas_report.to_notebook_iframe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Correlation Study"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Before we check the correlation rates of our variables against the Sale Price, we will use One Hot Encoding on our categorical variables.\n",
        "* In order to use our correlation methods, our categorical variables need to be numbers.  One Hot Encoding will allow us to easily see the original values as they split the categorical variables into new columns and assign them a binary value of '1' or '0'.\n",
        "* To carry out One Hot Encoding, we first need to handle the missing variable in our categorical columns and as we can see above in our dataset, there are a number of columns with missing data. \n",
        "* Let's check which columns with missing data below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vars_with_missing_data = df[df.columns[df.isna().sum() > 0]]\n",
        "vars_with_missing_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We will take a list of the categorical variables from this DataFrame to use with our One Hot Encoder and will impute the most frequent value for any missing values for each column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cat_vars_with_na = (vars_with_missing_data\n",
        "                    .columns[vars_with_missing_data.dtypes == 'object']\n",
        "                    .to_list())\n",
        "cat_vars_with_na"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We impute the missing values with CategoricalImputer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from feature_engine.imputation import CategoricalImputer\n",
        "categorical_imputer = CategoricalImputer(imputation_method='frequent',\n",
        "                                         variables=cat_vars_with_na)\n",
        "df = categorical_imputer.fit_transform(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Let's check our DataSet to ensure there is no missing values for ['BsmtFinType1', 'GarageFinish']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.filter(cat_vars_with_na).info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We use OneHotEncoder and declare a new DataFrame with our new columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from feature_engine.encoding import OneHotEncoder\n",
        "encoder = OneHotEncoder(variables=cat_vars_with_na, drop_last=False)\n",
        "df_ohe = encoder.fit_transform(df)\n",
        "print(df_ohe.shape)\n",
        "df_ohe.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We will use both person and spearman methods to check the levels of correlation between variables and 'SalePrice'. We will exclude 'SalePrice' from our results and check the 5 most highly correlated varibales for each method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_pearson = (df_ohe.corr(method='pearson')['SalePrice']\n",
        "             .sort_values(key=abs, ascending=False)[1:].head(5))\n",
        "df_pearson"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_spearman = (df_ohe.corr(method='spearman')['SalePrice']\n",
        "              .sort_values(key=abs, ascending=False)[1:].head(5))\n",
        "df_spearman"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* The methods produce similar enough results.\n",
        "* 'OverallQual' is the most highly correlated variable in each case and only 'YearBuilt' & '1stFlrSF' do not show up in each\n",
        "* Let's list out the variables to study in a set to remove any duplicates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cols_to_study = set(df_spearman.index.to_list()+df_pearson.index.to_list())\n",
        "cols_to_study"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We create a new DataFrame with the variables most closely correlated with Sales Price"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_eda = df_ohe.filter(['1stFlrSF', 'GarageArea', 'GrLivArea', 'OverallQual',\n",
        "                        'TotalBsmtSF', 'YearBuilt', 'SalePrice'])\n",
        "df_eda.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Visualisation\n",
        "* We now want to plot out our data in order to show how these variables correlate to Sales Prices.\n",
        "* 'SalePrice' as a variable has a large range of values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "min_val = int(df_eda.filter(['SalePrice']).min())\n",
        "max_val = int(df_eda.filter(['SalePrice']).max())\n",
        "count = df_eda.shape[0]\n",
        "\n",
        "print(f\"There are {count} values in the SalePrice column ranging from\" +\n",
        "      \" {min_val} to {max_val}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* For this reason, to simplify the visiualisation of our Sale Prices, we will seperate the values into 6 quantiles which will represent ranges of values and display more clearly on histograms.\n",
        "* We will do so using EqualFrequencyDiscretiser.\n",
        "* We fit and transform our data below:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from feature_engine.discretisation import EqualFrequencyDiscretiser\n",
        "discretiser = EqualFrequencyDiscretiser(q=6, variables=['SalePrice'])\n",
        "discretiser.fit(df_eda)\n",
        "df_eda = discretiser.transform(df_eda)\n",
        "df_eda"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We confirm our 'SalePrice' variable has been split up into equal quantiles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "sns.histplot(data=df_eda, x='SalePrice')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* This has worked, however it is not clear what range the values of 0 - 5 represent.\n",
        "* We will check how the range of values has been discretised"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "discretiser.binner_dict_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We will assign these ranges to the values they represent in a dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels = discretiser.binner_dict_['SalePrice']\n",
        "q_value = len(labels)-1\n",
        "labels_map = {}\n",
        "\n",
        "for x in range(0, q_value):\n",
        "    if x == 0:\n",
        "        labels_map[x] = f\"< {int(labels[1])}\"\n",
        "    elif x < q_value - 1:\n",
        "        labels_map[x] = f\"{int(labels[x])} - {int(labels[x+1])}\"\n",
        "    else:\n",
        "        labels_map[x] = f\"{int(labels[x])} +\"\n",
        "\n",
        "labels_map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We apply these values to our DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_eda[\"SalePrice\"] = df_eda[\"SalePrice\"].replace(labels_map)\n",
        "df_eda"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We define the hue_order for our histograms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "hue_order = labels_map.values()\n",
        "list(hue_order)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We will plot our correlated variables on histograms below.\n",
        "    * plot_numerical() function adapted from CI Lesson: *Exploratory Data Analysis > Exploratory Data Analysis Tools > Correlation Unit 2: Analysis*\n",
        "* We will also plot accompanying lineplots on the original dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "sns.set_style('whitegrid')\n",
        "\n",
        "\n",
        "def plot_numerical(df, col, target_var, hue_order):\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    sns.histplot(data=df, x=col, hue=target_var, hue_order=hue_order, kde=True,\n",
        "                 element=\"step\")\n",
        "    plt.title(f\"{col}\", fontsize=20, y=1.05)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_line(df, col, target_var):\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    sns.lineplot(data=df, x=target_var, y=col, color='#FC6C85')\n",
        "    plt.title(f\"{col}\", fontsize=20, y=1.05)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "target_var = 'SalePrice'\n",
        "for col in ['1stFlrSF', 'GarageArea', 'GrLivArea', 'OverallQual',\n",
        "            'TotalBsmtSF', 'YearBuilt']:\n",
        "    plot_numerical(df_eda, col, target_var, hue_order)\n",
        "    plot_line(df, col, target_var)\n",
        "    print(\"\\n\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusions\n",
        "* Houses with high Sales Prices tend to have first floors with at least 1500 square feet.\n",
        "\n",
        "* Houses with low Sales Prices tend to have no garage and those with a garage of at least 600 square feet tend to have high Sales Prices.\n",
        "\n",
        "* Houses with high sales prices tend to have above grade living area of at least 1500 square feet. Those with low sales prices tend to have 1000 square feet or less.\n",
        "\n",
        "* Houses with high Sales prices tend to have at least a Very Good Overall Quality Rating.\n",
        "\n",
        "* Houses with high Sales Prices tend to have basements with at a square footage of at least 1200. Houses with no basements or basements with less than 1000 square feet tend to have low Sales prices.\n",
        "\n",
        "* Houses do not tend to have a high Sales Price if built before 1990.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Testing our Hypotheses\n",
        "\n",
        "* Next, as part of Sale Price Study, we will test our hypotheses and will do so using correlation studies:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **1. Larger houses will tend to have sell at a higher price.**\n",
        "\n",
        "* We will test this by checking whether properties with higher values for '1stFlrSF' tend to have higher Sales Prices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* If we suspect that properties with greater 1st Floor square footage will generally have a higher sales price, then we could expect a linear correlation between the variables '1stFlrSF' & 'SalePrice'.\n",
        "* Therefore, we will check the pearson correlation levels between these variables:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_pearson = df.corr(method='pearson')['SalePrice'].filter(['1stFlrSF'])\n",
        "df_pearson"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* As we can see, the level of pearson correlation between the varaibles is 0.61, which is relatively high.\n",
        "* This does not necessarily confirm that larger properties have higher sales prices, but we can use a scatterplot to visualise the data and gleam a better understanding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x, y = '1stFlrSF', 'SalePrice'\n",
        "fig, axes = plt.subplots(figsize=(12, 6))\n",
        "sns.scatterplot(data=df, x=x, y=y)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We can see there is a general trend in higher SalePrice values when there is higher 1st Floor Square Footage.\n",
        "* It is not hugely pronounced, hwoever, we can note that there are no houses worth less than $100,000 where the '1stFlrSF' value is higher than 1500.\n",
        "* We can also examine the y-axis and note that there are no Sale Prices greater than $300,000 where the '1stFlrSF' value is less than 1000.\n",
        "* If we examine our histogram from our previous study, we can see that houses in the higher range of Sale Prices tend to have at least 1500 first floor square footage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_numerical(df_eda, '1stFlrSF', 'SalePrice', hue_order)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Our correlation sutdy and visualisations support our hypothesis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **2. The overall condition of the house will result in a higher sale price.**\n",
        "* We will check how OverallCond ratings correlated to SalePrice and also check whether homes with similar values for '1stFlrSF', with greater OverallCond, tend to have greater Sale prices."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Similar to our first hypothesis, we should suspect a that the OverallCond might correlate linearly with the SalePrice if a higher rating is to result in a higher Sale price.\n",
        "* We will check the level of pearson correlation bewteen the variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_pearson = df.corr(method='pearson')['SalePrice'].filter(['OverallCond'])\n",
        "df_pearson"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* The level of linear correlation between the 'OverallCond' & 'SalePrice' is 0.08, which is very low and does not suggest that the overall condition rating is a strong factor in the Sale Price.\n",
        "* This does not support our hypothesis, however, there are numerous variables which affect the Sale Price, so it may be the case that the Overall Condiiton rating of a house may play a larger role when taking houses of similar size into account. This forms part of our hypothesis, so we will try and validate this.\n",
        "* To do so, we willneed to group houses of similar 1st floor square footage together, so we will discretize the column values and convert the variable to a categorical variable.\n",
        "* We will use EqualFrequencyDiscretiser to do so but also Outlier Trimmer in order to have more accurate ranges of '1stFlrSF'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Outlier Trimmer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from feature_engine.outliers import OutlierTrimmer\n",
        "df_hyp = df.copy()\n",
        "outlier_trimmer = OutlierTrimmer(capping_method='iqr', fold=1.5, tail='both',\n",
        "                                 variables=['1stFlrSF'])\n",
        "df_hyp = outlier_trimmer.fit_transform(df_hyp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Discretisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "discretiser = EqualFrequencyDiscretiser(q=6, variables=['1stFlrSF'])\n",
        "discretiser.fit(df_hyp)\n",
        "df_hyp = discretiser.transform(df_hyp)\n",
        "df_hyp.filter(['1stFlrSF']).head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Confirm the range of values has been split into 4 categories with equal counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.set_theme(style=\"whitegrid\")\n",
        "sns.histplot(data=df_hyp, x='1stFlrSF')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We check how the range of values has been discretised"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "discretiser.binner_dict_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We assign these ranges to the values which they represent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels = discretiser.binner_dict_['1stFlrSF']\n",
        "q_value = len(labels)-1\n",
        "labels_map = {}\n",
        "\n",
        "for x in range(0, q_value):\n",
        "    if x == 0:\n",
        "        labels_map[x] = f\"< {int(labels[1])}\"\n",
        "    elif x < q_value - 1:\n",
        "        labels_map[x] = f\"{int(labels[x])} - {int(labels[x+1])}\"\n",
        "    else:\n",
        "        labels_map[x] = f\"{int(labels[x])} +\"\n",
        "\n",
        "labels_map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We apply these to df_hyp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_hyp['1stFlrSF'] = df_hyp['1stFlrSF'].replace(labels_map)\n",
        "df_hyp.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "order = labels_map.values()\n",
        "list(order)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We will now visualise '1stFlrSF' against 'SalePrice' and use a hue to represent the 'OverallCond' ratings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x, y = '1stFlrSF', 'SalePrice'\n",
        "fig, axes = plt.subplots(figsize=(12, 6))\n",
        "sns.stripplot(data=df_hyp, x=x, y=y, hue='OverallCond', order=order)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* From looking at our strip plot, we can see that generally the most frequent rating for the most expensive properties for each '1stFlrSF' range is 5, which is not completely surprising as it is the most frequent rating in our dataset.\n",
        "* We can also see that any property rated 2 or below tend to be towards the bottom in terms of Sale price.\n",
        "* It is not totally clear from our plot, that a higher rating will translate to a higher Sale Price for similarly sized properties:\n",
        "    * Some 9 rated properties can be seen at the top of some ranges but looking at 1516+ for example, there are properties rated 9 which are towards the bottom.\n",
        "    * If we look throughout each range and only take ratings of 7+ into account, they seem to be spread accross the range of Sale Prices for each quantile of 1t floor square foot.\n",
        "* With these arguments and the low level of correlation studied earlier, our correlation study does not validate our hypothesis, but rather contradicts it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **3. Houses with Garages will tend to have a higher sales price than those without and those with large garages will tend to sell at higher prices.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We again will test this hypothesis using a correlation study and visualisations.\n",
        "* We would again suspect that the GarageArea might correlate linearly with the SalePrice if a larger garage is to result in a higher Sale price.\n",
        "* We will check the level of pearson correlation bewteen the variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_pearson = df.corr(method='pearson')['SalePrice'].filter(['GarageArea'])\n",
        "df_pearson"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* This is a relatively high score. It appears that the size of the Garage will likely lead to a higher sales price.\n",
        "* We will plot the data out and check that it confirms this idea.\n",
        "* We can use the plot from our previous correlation study and inspect."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_numerical(df_eda, 'GarageArea', 'SalePrice', hue_order)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* It seems clear from our histogram that the trend of larger garages results in a higher sale price. \n",
        "    * The higher range of Sale Prices are concentrated in the higher end of the scale when it comes to Garage Area and apart from a few outliers, almost all properties with the largest garages have high sale prices.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* It is also clear from the high number of properties with sale prices of less than $118,500, that properties without garages ('GarageArea'=0) will tend to have a lower sale price than those that do.\n",
        "    * There are come properties sold without garages in the higher range of sale prices, but these are a minority.\n",
        "    * It can also be seen, that outside of properties with no garage, the bulk of properties with sale prices of less than $118,500, have garages which fall between 200 and 400 square foot."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Our correlation study in this case validates our hypothesis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Next Steps\n",
        "\n",
        "* We have completed our first business requirment and generated content for our dashboard.\n",
        "* The next action is to move on to business requirment 2 and build an ML pipeline to predict the sale price of the inherited homes and any other homes in Ames, Iowa.\n",
        "* There are no files to push to repo from this notebook."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12 (default, Oct 14 2022, 17:27:18) \n[GCC 9.4.0]"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
