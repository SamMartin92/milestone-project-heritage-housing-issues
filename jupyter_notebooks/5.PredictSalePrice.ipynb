{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **(ADD HERE THE NOTEBOOK NAME)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Write here your notebook objective, for example, \"Fetch data from Kaggle and save as raw data\", or \"engineer features for modelling\"\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* Write here which data or information you need to run the notebook \n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Write here which files, code or artifacts you generate by the end of the notebook \n",
        "\n",
        "## CRISP-DM\n",
        "\n",
        "* Modelling\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We are assuming you will store the notebooks in a sub folder, therefore when running the notebook in the editor, you will need to change the working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/workspace/milestone-project-heritage-housing-issues/jupyter_notebooks'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You set a new current directory\n"
          ]
        }
      ],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/workspace/milestone-project-heritage-housing-issues'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1460, 22)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1stFlrSF</th>\n",
              "      <th>2ndFlrSF</th>\n",
              "      <th>BedroomAbvGr</th>\n",
              "      <th>BsmtExposure</th>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <th>BsmtFinType1</th>\n",
              "      <th>BsmtUnfSF</th>\n",
              "      <th>GarageArea</th>\n",
              "      <th>GarageFinish</th>\n",
              "      <th>GarageYrBlt</th>\n",
              "      <th>...</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>MasVnrArea</th>\n",
              "      <th>OpenPorchSF</th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>TotalBsmtSF</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YearRemodAdd</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>856</td>\n",
              "      <td>854.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>No</td>\n",
              "      <td>706</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>150</td>\n",
              "      <td>548</td>\n",
              "      <td>RFn</td>\n",
              "      <td>2003.0</td>\n",
              "      <td>...</td>\n",
              "      <td>8450</td>\n",
              "      <td>65.0</td>\n",
              "      <td>196.0</td>\n",
              "      <td>61</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>856</td>\n",
              "      <td>2003</td>\n",
              "      <td>2003</td>\n",
              "      <td>208500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1262</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Gd</td>\n",
              "      <td>978</td>\n",
              "      <td>ALQ</td>\n",
              "      <td>284</td>\n",
              "      <td>460</td>\n",
              "      <td>RFn</td>\n",
              "      <td>1976.0</td>\n",
              "      <td>...</td>\n",
              "      <td>9600</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>1262</td>\n",
              "      <td>1976</td>\n",
              "      <td>1976</td>\n",
              "      <td>181500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>920</td>\n",
              "      <td>866.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Mn</td>\n",
              "      <td>486</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>434</td>\n",
              "      <td>608</td>\n",
              "      <td>RFn</td>\n",
              "      <td>2001.0</td>\n",
              "      <td>...</td>\n",
              "      <td>11250</td>\n",
              "      <td>68.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>42</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>920</td>\n",
              "      <td>2001</td>\n",
              "      <td>2002</td>\n",
              "      <td>223500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>961</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>No</td>\n",
              "      <td>216</td>\n",
              "      <td>ALQ</td>\n",
              "      <td>540</td>\n",
              "      <td>642</td>\n",
              "      <td>Unf</td>\n",
              "      <td>1998.0</td>\n",
              "      <td>...</td>\n",
              "      <td>9550</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>35</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>756</td>\n",
              "      <td>1915</td>\n",
              "      <td>1970</td>\n",
              "      <td>140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1145</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Av</td>\n",
              "      <td>655</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>490</td>\n",
              "      <td>836</td>\n",
              "      <td>RFn</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>...</td>\n",
              "      <td>14260</td>\n",
              "      <td>84.0</td>\n",
              "      <td>350.0</td>\n",
              "      <td>84</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>1145</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>250000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 22 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   1stFlrSF  2ndFlrSF  BedroomAbvGr BsmtExposure  BsmtFinSF1 BsmtFinType1  \\\n",
              "0       856     854.0           3.0           No         706          GLQ   \n",
              "1      1262       0.0           3.0           Gd         978          ALQ   \n",
              "2       920     866.0           3.0           Mn         486          GLQ   \n",
              "3       961       NaN           NaN           No         216          ALQ   \n",
              "4      1145       NaN           4.0           Av         655          GLQ   \n",
              "\n",
              "   BsmtUnfSF  GarageArea GarageFinish  GarageYrBlt  ...  LotArea LotFrontage  \\\n",
              "0        150         548          RFn       2003.0  ...     8450        65.0   \n",
              "1        284         460          RFn       1976.0  ...     9600        80.0   \n",
              "2        434         608          RFn       2001.0  ...    11250        68.0   \n",
              "3        540         642          Unf       1998.0  ...     9550        60.0   \n",
              "4        490         836          RFn       2000.0  ...    14260        84.0   \n",
              "\n",
              "   MasVnrArea  OpenPorchSF  OverallCond  OverallQual  TotalBsmtSF  YearBuilt  \\\n",
              "0       196.0           61            5            7          856       2003   \n",
              "1         0.0            0            8            6         1262       1976   \n",
              "2       162.0           42            5            7          920       2001   \n",
              "3         0.0           35            5            7          756       1915   \n",
              "4       350.0           84            5            8         1145       2000   \n",
              "\n",
              "   YearRemodAdd  SalePrice  \n",
              "0          2003     208500  \n",
              "1          1976     181500  \n",
              "2          2002     223500  \n",
              "3          1970     140000  \n",
              "4          2000     250000  \n",
              "\n",
              "[5 rows x 22 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = (pd.read_csv(f\"inputs/datasets/unzipped/house_prices_records.csv\")\n",
        "        .drop(labels=['EnclosedPorch', 'WoodDeckSF'],axis=1))\n",
        "print(df.shape)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "arbitrary_imputation_vars = ['2ndFlrSF']\n",
        "median_imputation_vars = ['BedroomAbvGr', 'LotFrontage','GarageYrBlt','MasVnrArea']\n",
        "most_frequent_vars = ['BsmtFinType1']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['BsmtExposure', 'BsmtFinType1', 'GarageFinish', 'KitchenQual']"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "categorical_encoding_vars =df.select_dtypes(include=['object']).columns.to_list()\n",
        "categorical_encoding_vars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "log_transformation_vars = ['1stFlrSF', 'LotArea']\n",
        "yeojohnson_vars = ['GrLivArea']\n",
        "boxcox_vars =[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['1stFlrSF',\n",
              " '2ndFlrSF',\n",
              " 'BedroomAbvGr',\n",
              " 'BsmtExposure',\n",
              " 'BsmtFinSF1',\n",
              " 'BsmtFinType1',\n",
              " 'BsmtUnfSF',\n",
              " 'GarageArea',\n",
              " 'GarageFinish',\n",
              " 'GarageYrBlt',\n",
              " 'GrLivArea',\n",
              " 'KitchenQual',\n",
              " 'LotArea',\n",
              " 'LotFrontage',\n",
              " 'MasVnrArea',\n",
              " 'OpenPorchSF',\n",
              " 'OverallCond',\n",
              " 'OverallQual',\n",
              " 'TotalBsmtSF',\n",
              " 'YearBuilt',\n",
              " 'YearRemodAdd']"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "smart_correlation_features = df.columns.to_list() \n",
        "smart_correlation_features.pop()\n",
        "smart_correlation_features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We Will handle Data cleaning for 'GarageFinish' outside of the pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1460 entries, 0 to 1459\n",
            "Data columns (total 1 columns):\n",
            " #   Column        Non-Null Count  Dtype \n",
            "---  ------        --------------  ----- \n",
            " 0   GarageFinish  1460 non-null   object\n",
            "dtypes: object(1)\n",
            "memory usage: 11.5+ KB\n"
          ]
        }
      ],
      "source": [
        "nan_GarageFinish_vals=df[df['GarageFinish'].isna()]\n",
        "nan_GarageFinish_index = list(nan_GarageFinish_vals.index.values)\n",
        "\n",
        "df['GarageFinish'] = df['GarageFinish'].fillna(0)\n",
        "\n",
        "for x in nan_GarageFinish_index:\n",
        "    garage_area_value = df.iloc[x,8]\n",
        "    if garage_area_value == 0:\n",
        "        df.at[x,'GarageFinish'] = 'None'\n",
        "    else:\n",
        "        df.at[x,'GarageFinish'] = 'Unf'\n",
        "\n",
        "df.filter(['GarageFinish']).info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Create ML Pipelines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Data Cleaning and Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Pipeline(steps=[('ArbitraryImputer',\n",
              "                 ArbitraryNumberImputer(arbitrary_number=0,\n",
              "                                        variables=['2ndFlrSF'])),\n",
              "                ('MedianImputation',\n",
              "                 MeanMedianImputer(variables=['BedroomAbvGr', 'LotFrontage',\n",
              "                                              'GarageYrBlt', 'MasVnrArea'])),\n",
              "                ('CategoricalImputer',\n",
              "                 CategoricalImputer(imputation_method='frequent',\n",
              "                                    variables=['BsmtFinType1'])),\n",
              "                ('OrdinalCategoricalEncoder',\n",
              "                 OrdinalEnco...\n",
              "                 SmartCorrelatedSelection(selection_method='variance',\n",
              "                                          threshold=0.6,\n",
              "                                          variables=['1stFlrSF', '2ndFlrSF',\n",
              "                                                     'BedroomAbvGr',\n",
              "                                                     'BsmtExposure',\n",
              "                                                     'BsmtFinSF1',\n",
              "                                                     'BsmtFinType1',\n",
              "                                                     'BsmtUnfSF', 'GarageArea',\n",
              "                                                     'GarageFinish',\n",
              "                                                     'GarageYrBlt', 'GrLivArea',\n",
              "                                                     'KitchenQual', 'LotArea',\n",
              "                                                     'LotFrontage',\n",
              "                                                     'MasVnrArea',\n",
              "                                                     'OpenPorchSF',\n",
              "                                                     'OverallCond',\n",
              "                                                     'OverallQual',\n",
              "                                                     'TotalBsmtSF', 'YearBuilt',\n",
              "                                                     'YearRemodAdd']))])"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "### Data Cleaning\n",
        "from feature_engine.imputation import MeanMedianImputer\n",
        "from feature_engine.imputation import ArbitraryNumberImputer\n",
        "from feature_engine.imputation import CategoricalImputer\n",
        "\n",
        "### Feature Engineering\n",
        "from feature_engine.selection import SmartCorrelatedSelection\n",
        "from feature_engine.encoding import OrdinalEncoder\n",
        "from feature_engine import transformation as vt\n",
        "\n",
        "def PipelineDataCleaningAndFeatureEngineering():\n",
        "  pipeline_base = Pipeline([\n",
        "    (\"ArbitraryImputer\", ArbitraryNumberImputer(arbitrary_number=0,\n",
        "                                            variables=arbitrary_imputation_vars)),\n",
        "                                \n",
        "    (\"MedianImputation\", MeanMedianImputer(imputation_method='median',\n",
        "                                            variables=median_imputation_vars)),\n",
        "    \n",
        "    (\"CategoricalImputer\", CategoricalImputer(imputation_method='frequent', \n",
        "                                        variables=most_frequent_vars)),\n",
        "\n",
        "    (\"OrdinalCategoricalEncoder\",OrdinalEncoder(encoding_method='arbitrary', \n",
        "                                                variables = categorical_encoding_vars)),\n",
        "    \n",
        "    (\"LogTransformer\", vt.YeoJohnsonTransformer(variables = yeojohnson_vars)),\n",
        "\n",
        "    (\"YeoJohnsonTransformer\", vt.YeoJohnsonTransformer(variables = yeojohnson_vars)),\n",
        "\n",
        "    # (\"BoxCoxTransformer\", vt.BoxCoxTransformer(variables = boxcox_vars)),\n",
        "      \n",
        "    (\"SmartCorrelatedSelection\",SmartCorrelatedSelection(variables=smart_correlation_features, \n",
        "                                                          method=\"pearson\", threshold=0.6, \n",
        "                                                          selection_method=\"variance\") ),\n",
        "       \n",
        "  ])\n",
        "\n",
        "  return pipeline_base\n",
        "\n",
        "PipelineDataCleaningAndFeatureEngineering()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "# ML Pipeline for Modelling and Hyperparameter Optimization\n",
        "\n",
        "* Our next step is choosing the optimal algorithm for our ML model and the most effective hyperparameter for our selected algorithm\n",
        "* We will do so with the below function and custom class.\n",
        "    * Below code taken from CI lesson: *Scikit-Learn Unit 6: Cross Validation Search Part 2*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "### Feat Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "### Feat Selection\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "### ML algorithms \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import LinearRegression \n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "def PipelineRegressor(model):\n",
        "  pipeline_base = Pipeline([\n",
        "     \n",
        "       (\"scaler\",StandardScaler() ),\n",
        "       (\"feat_selection\",SelectFromModel(model) ),\n",
        "       (\"model\",model ),\n",
        "  ])\n",
        "\n",
        "  return pipeline_base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "class HyperparameterOptimizationSearch:\n",
        "\n",
        "    def __init__(self, models, params):\n",
        "        self.models = models\n",
        "        self.params = params\n",
        "        self.keys = models.keys()\n",
        "        self.grid_searches = {}\n",
        "\n",
        "    def fit(self, X, y, cv, n_jobs, verbose=1, scoring=None, refit=False):\n",
        "        for key in self.keys:\n",
        "            print(f\"\\nRunning GridSearchCV for {key} \\n\")\n",
        "\n",
        "            model =  PipelineClf(self.models[key])\n",
        "            params = self.params[key]\n",
        "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs, verbose=verbose, scoring=scoring, )\n",
        "            gs.fit(X,y)\n",
        "            self.grid_searches[key] = gs    \n",
        "\n",
        "    def score_summary(self, sort_by='mean_score'):\n",
        "        def row(key, scores, params):\n",
        "            d = {\n",
        "                 'estimator': key,\n",
        "                 'min_score': min(scores),\n",
        "                 'max_score': max(scores),\n",
        "                 'mean_score': np.mean(scores),\n",
        "                 'std_score': np.std(scores),\n",
        "            }\n",
        "            return pd.Series({**params,**d})\n",
        "\n",
        "        rows = []\n",
        "        for k in self.grid_searches:\n",
        "            params = self.grid_searches[k].cv_results_['params']\n",
        "            scores = []\n",
        "            for i in range(self.grid_searches[k].cv):\n",
        "                key = \"split{}_test_score\".format(i)\n",
        "                r = self.grid_searches[k].cv_results_[key]        \n",
        "                scores.append(r.reshape(len(params),1))\n",
        "\n",
        "            all_scores = np.hstack(scores)\n",
        "            for p, s in zip(params,all_scores):\n",
        "                rows.append((row(k, s, p)))\n",
        "\n",
        "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
        "        columns = ['estimator', 'min_score', 'mean_score', 'max_score', 'std_score']\n",
        "        columns = columns + [c for c in df.columns if c not in columns]\n",
        "        return df[columns], self.grid_searches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Split Train & Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1168, 21) (1168,) (292, 21) (292,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test,y_train, y_test = train_test_split(\n",
        "                                    df.drop(['SalePrice'],axis=1),\n",
        "                                    df['SalePrice'],\n",
        "                                    test_size = 0.2,\n",
        "                                    random_state = 0,\n",
        "                                    )\n",
        "\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We apply our first pipeline to our train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1168, 17) (1168,) (292, 17) (292,)\n"
          ]
        }
      ],
      "source": [
        "pipeline_data_cleaning_feat_eng = PipelineDataCleaningAndFeatureEngineering()\n",
        "X_train = pipeline_data_cleaning_feat_eng.fit_transform(X_train)\n",
        "X_test = pipeline_data_cleaning_feat_eng.transform(X_test)\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Scikit Learn Cross Validation Search\n",
        "\n",
        "* We first search for the most suitable algorithm using tandard hyper parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "models_quick_search = {\n",
        "    # \"LogisticRegression\": LogisticRegression(random_state=0),\n",
        "    \"LinearRegression\": LinearRegression(),\n",
        "    \"GradientBoostingRegressor\": GradientBoostingRegressor(random_state=0), \n",
        "    \"XGBRegressor\": XGBRegressor(random_state=0),\n",
        "    \"DecisionTreeRegressor\": DecisionTreeRegressor(random_state=0),\n",
        "    \"RandomForestRegressor\": RandomForestRegressor(random_state=0),\n",
        "    \"ExtraTreesRegressor\": ExtraTreesRegressor(random_state=0),\n",
        "    \"AdaBoostRegressor\": AdaBoostRegressor(random_state=0),\n",
        "}\n",
        "\n",
        "params_quick_search = {\n",
        "    # \"LogisticRegression\":{},\n",
        "    \"LinearRegression\": {},\n",
        "    \"GradientBoostingRegressor\": {},\n",
        "    \"XGBRegressor\":{},\n",
        "    \"DecisionTreeRegressor\":{},\n",
        "    \"RandomForestRegressor\":{},\n",
        "    \"GradientBoostingClassifier\":{},\n",
        "    \"ExtraTreesRegressor\":{},\n",
        "    \"AdaBoostRegressor\":{},\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* At this stage we made an attempt at finding the best algorithm for out model, and set our cross validation value, initially, to cv=2, to allow LogisticRegression to run.\n",
        "* Logistic regression scored worse that other algorithms, so we have commented it out above, in order to allow a more extensive search wit a cross validation value of cv=5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running GridSearchCV for LinearRegression \n",
            "\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/pipeline.py\", line 341, in fit\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/pipeline.py\", line 303, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/joblib/memory.py\", line 352, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/base.py\", line 702, in fit_transform\n",
            "    return self.fit(X, y, **fit_params).transform(X)\n",
            "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/feature_engine/imputation/mean_median.py\", line 96, in fit\n",
            "    self.variables = _find_or_check_numerical_variables(X, self.variables)\n",
            "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/feature_engine/variable_manipulation.py\", line 76, in _find_or_check_numerical_variables\n",
            "    if any(X[variables].select_dtypes(exclude=\"number\").columns):\n",
            "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/pandas/core/frame.py\", line 3511, in __getitem__\n",
            "    indexer = self.columns._get_indexer_strict(key, \"columns\")[1]\n",
            "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 5782, in _get_indexer_strict\n",
            "    self._raise_if_missing(keyarr, indexer, axis_name)\n",
            "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 5845, in _raise_if_missing\n",
            "    raise KeyError(f\"{not_found} not in index\")\n",
            "KeyError: \"['GarageYrBlt'] not in index\"\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/pipeline.py\", line 341, in fit\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/pipeline.py\", line 303, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/joblib/memory.py\", line 352, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/base.py\", line 702, in fit_transform\n",
            "    return self.fit(X, y, **fit_params).transform(X)\n",
            "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/feature_engine/imputation/mean_median.py\", line 96, in fit\n",
            "    self.variables = _find_or_check_numerical_variables(X, self.variables)\n",
            "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/feature_engine/variable_manipulation.py\", line 76, in _find_or_check_numerical_variables\n",
            "    if any(X[variables].select_dtypes(exclude=\"number\").columns):\n",
            "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/pandas/core/frame.py\", line 3511, in __getitem__\n",
            "    indexer = self.columns._get_indexer_strict(key, \"columns\")[1]\n",
            "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 5782, in _get_indexer_strict\n",
            "    self._raise_if_missing(keyarr, indexer, axis_name)\n",
            "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 5845, in _raise_if_missing\n",
            "    raise KeyError(f\"{not_found} not in index\")\n",
            "KeyError: \"['GarageYrBlt'] not in index\"\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/pipeline.py\", line 341, in fit\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/pipeline.py\", line 303, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/joblib/memory.py\", line 352, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/base.py\", line 702, in fit_transform\n",
            "    return self.fit(X, y, **fit_params).transform(X)\n",
            "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/feature_engine/imputation/mean_median.py\", line 96, in fit\n",
            "    self.variables = _find_or_check_numerical_variables(X, self.variables)\n",
            "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/feature_engine/variable_manipulation.py\", line 76, in _find_or_check_numerical_variables\n",
            "    if any(X[variables].select_dtypes(exclude=\"number\").columns):\n",
            "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/pandas/core/frame.py\", line 3511, in __getitem__\n",
            "    indexer = self.columns._get_indexer_strict(key, \"columns\")[1]\n",
            "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 5782, in _get_indexer_strict\n",
            "    self._raise_if_missing(keyarr, indexer, axis_name)\n",
            "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 5845, in _raise_if_missing\n",
            "    raise KeyError(f\"{not_found} not in index\")\n",
            "KeyError: \"['GarageYrBlt'] not in index\"\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/pipeline.py\", line 341, in fit\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/pipeline.py\", line 303, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/joblib/memory.py\", line 352, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/base.py\", line 702, in fit_transform\n",
            "    return self.fit(X, y, **fit_params).transform(X)\n",
            "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/feature_engine/imputation/mean_median.py\", line 96, in fit\n",
            "    self.variables = _find_or_check_numerical_variables(X, self.variables)\n",
            "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/feature_engine/variable_manipulation.py\", line 76, in _find_or_check_numerical_variables\n",
            "    if any(X[variables].select_dtypes(exclude=\"number\").columns):\n",
            "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/pandas/core/frame.py\", line 3511, in __getitem__\n",
            "    indexer = self.columns._get_indexer_strict(key, \"columns\")[1]\n",
            "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 5782, in _get_indexer_strict\n",
            "    self._raise_if_missing(keyarr, indexer, axis_name)\n",
            "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 5845, in _raise_if_missing\n",
            "    raise KeyError(f\"{not_found} not in index\")\n",
            "KeyError: \"['GarageYrBlt'] not in index\"\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
            "/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/pipeline.py\", line 341, in fit\n",
            "    Xt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/pipeline.py\", line 303, in _fit\n",
            "    X, fitted_transformer = fit_transform_one_cached(\n",
            "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/joblib/memory.py\", line 352, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/pipeline.py\", line 754, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/base.py\", line 702, in fit_transform\n",
            "    return self.fit(X, y, **fit_params).transform(X)\n",
            "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/feature_engine/imputation/mean_median.py\", line 96, in fit\n",
            "    self.variables = _find_or_check_numerical_variables(X, self.variables)\n",
            "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/feature_engine/variable_manipulation.py\", line 76, in _find_or_check_numerical_variables\n",
            "    if any(X[variables].select_dtypes(exclude=\"number\").columns):\n",
            "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/pandas/core/frame.py\", line 3511, in __getitem__\n",
            "    indexer = self.columns._get_indexer_strict(key, \"columns\")[1]\n",
            "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 5782, in _get_indexer_strict\n",
            "    self._raise_if_missing(keyarr, indexer, axis_name)\n",
            "  File \"/workspace/.pip-modules/lib/python3.8/site-packages/pandas/core/indexes/base.py\", line 5845, in _raise_if_missing\n",
            "    raise KeyError(f\"{not_found} not in index\")\n",
            "KeyError: \"['GarageYrBlt'] not in index\"\n",
            "\n",
            "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
          ]
        },
        {
          "ename": "NotFittedError",
          "evalue": "All estimators failed to fit",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [60], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m make_scorer, r2_score\n\u001b[1;32m      2\u001b[0m search \u001b[39m=\u001b[39m HyperparameterOptimizationSearch(models\u001b[39m=\u001b[39mmodels_quick_search, params\u001b[39m=\u001b[39mparams_quick_search)\n\u001b[0;32m----> 3\u001b[0m search\u001b[39m.\u001b[39;49mfit(X_train, y_train, \n\u001b[1;32m      4\u001b[0m             scoring\u001b[39m=\u001b[39;49mmake_scorer(r2_score), n_jobs\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, cv\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m)\n",
            "Cell \u001b[0;32mIn [58], line 18\u001b[0m, in \u001b[0;36mHyperparameterOptimizationSearch.fit\u001b[0;34m(self, X, y, cv, n_jobs, verbose, scoring, refit)\u001b[0m\n\u001b[1;32m     16\u001b[0m params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams[key]\n\u001b[1;32m     17\u001b[0m gs \u001b[39m=\u001b[39m GridSearchCV(model, params, cv\u001b[39m=\u001b[39mcv, n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, scoring\u001b[39m=\u001b[39mscoring, )\n\u001b[0;32m---> 18\u001b[0m gs\u001b[39m.\u001b[39;49mfit(X,y)\n\u001b[1;32m     19\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgrid_searches[key] \u001b[39m=\u001b[39m gs\n",
            "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/utils/validation.py:63\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m extra_args \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(args) \u001b[39m-\u001b[39m \u001b[39mlen\u001b[39m(all_args)\n\u001b[1;32m     62\u001b[0m \u001b[39mif\u001b[39;00m extra_args \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39m# extra_args > 0\u001b[39;00m\n\u001b[1;32m     66\u001b[0m args_msg \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(name, arg)\n\u001b[1;32m     67\u001b[0m             \u001b[39mfor\u001b[39;00m name, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(kwonly_args[:extra_args],\n\u001b[1;32m     68\u001b[0m                                  args[\u001b[39m-\u001b[39mextra_args:])]\n",
            "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/model_selection/_search.py:841\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    835\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    836\u001b[0m         all_candidate_params, n_splits, all_out,\n\u001b[1;32m    837\u001b[0m         all_more_results)\n\u001b[1;32m    839\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 841\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    843\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    844\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    845\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m'\u001b[39m]\n",
            "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/model_selection/_search.py:1296\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1294\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1295\u001b[0m     \u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1296\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
            "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/model_selection/_search.py:827\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    822\u001b[0m \u001b[39m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[1;32m    823\u001b[0m \u001b[39m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[1;32m    824\u001b[0m \u001b[39m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[1;32m    825\u001b[0m \u001b[39m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[39mif\u001b[39;00m callable(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscoring):\n\u001b[0;32m--> 827\u001b[0m     _insert_error_scores(out, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merror_score)\n\u001b[1;32m    828\u001b[0m all_candidate_params\u001b[39m.\u001b[39mextend(candidate_params)\n\u001b[1;32m    829\u001b[0m all_out\u001b[39m.\u001b[39mextend(out)\n",
            "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:301\u001b[0m, in \u001b[0;36m_insert_error_scores\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    298\u001b[0m         successful_score \u001b[39m=\u001b[39m result[\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    300\u001b[0m \u001b[39mif\u001b[39;00m successful_score \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 301\u001b[0m     \u001b[39mraise\u001b[39;00m NotFittedError(\u001b[39m\"\u001b[39m\u001b[39mAll estimators failed to fit\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    303\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(successful_score, \u001b[39mdict\u001b[39m):\n\u001b[1;32m    304\u001b[0m     formatted_error \u001b[39m=\u001b[39m {name: error_score \u001b[39mfor\u001b[39;00m name \u001b[39min\u001b[39;00m successful_score}\n",
            "\u001b[0;31mNotFittedError\u001b[0m: All estimators failed to fit"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import make_scorer, r2_score\n",
        "search = HyperparameterOptimizationSearch(models=models_quick_search, params=params_quick_search)\n",
        "search.fit(X_train, y_train, \n",
        "            scoring=make_scorer(r2_score), n_jobs=-1, cv=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We add the results to a DataFrame and assess."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(729, 11)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>estimator</th>\n",
              "      <th>min_score</th>\n",
              "      <th>mean_score</th>\n",
              "      <th>max_score</th>\n",
              "      <th>std_score</th>\n",
              "      <th>model__learning_rate</th>\n",
              "      <th>model__max_depth</th>\n",
              "      <th>model__min_impurity_decrease</th>\n",
              "      <th>model__min_samples_split</th>\n",
              "      <th>model__min_weight_fraction_leaf</th>\n",
              "      <th>model__n_estimators</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>279</th>\n",
              "      <td>GradientBoostingRegressor</td>\n",
              "      <td>0.688071</td>\n",
              "      <td>0.788019</td>\n",
              "      <td>0.822261</td>\n",
              "      <td>0.05064</td>\n",
              "      <td>0.01</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>252</th>\n",
              "      <td>GradientBoostingRegressor</td>\n",
              "      <td>0.688071</td>\n",
              "      <td>0.788019</td>\n",
              "      <td>0.822261</td>\n",
              "      <td>0.05064</td>\n",
              "      <td>0.01</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>306</th>\n",
              "      <td>GradientBoostingRegressor</td>\n",
              "      <td>0.688071</td>\n",
              "      <td>0.788019</td>\n",
              "      <td>0.822261</td>\n",
              "      <td>0.05064</td>\n",
              "      <td>0.01</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270</th>\n",
              "      <td>GradientBoostingRegressor</td>\n",
              "      <td>0.687524</td>\n",
              "      <td>0.78782</td>\n",
              "      <td>0.822032</td>\n",
              "      <td>0.05083</td>\n",
              "      <td>0.01</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>297</th>\n",
              "      <td>GradientBoostingRegressor</td>\n",
              "      <td>0.687524</td>\n",
              "      <td>0.78782</td>\n",
              "      <td>0.822032</td>\n",
              "      <td>0.05083</td>\n",
              "      <td>0.01</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>GradientBoostingRegressor</td>\n",
              "      <td>-0.033214</td>\n",
              "      <td>0.067398</td>\n",
              "      <td>0.141992</td>\n",
              "      <td>0.071831</td>\n",
              "      <td>0.001</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>699</th>\n",
              "      <td>GradientBoostingRegressor</td>\n",
              "      <td>-0.033214</td>\n",
              "      <td>0.067398</td>\n",
              "      <td>0.141992</td>\n",
              "      <td>0.071831</td>\n",
              "      <td>0.001</td>\n",
              "      <td>None</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>555</th>\n",
              "      <td>GradientBoostingRegressor</td>\n",
              "      <td>-0.033214</td>\n",
              "      <td>0.067398</td>\n",
              "      <td>0.141992</td>\n",
              "      <td>0.071831</td>\n",
              "      <td>0.001</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>0.5</td>\n",
              "      <td>400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>546</th>\n",
              "      <td>GradientBoostingRegressor</td>\n",
              "      <td>-0.033214</td>\n",
              "      <td>0.067398</td>\n",
              "      <td>0.141992</td>\n",
              "      <td>0.071831</td>\n",
              "      <td>0.001</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>0.5</td>\n",
              "      <td>400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>510</th>\n",
              "      <td>GradientBoostingRegressor</td>\n",
              "      <td>-0.033214</td>\n",
              "      <td>0.067398</td>\n",
              "      <td>0.141992</td>\n",
              "      <td>0.071831</td>\n",
              "      <td>0.001</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>729 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                     estimator min_score mean_score max_score std_score  \\\n",
              "279  GradientBoostingRegressor  0.688071   0.788019  0.822261   0.05064   \n",
              "252  GradientBoostingRegressor  0.688071   0.788019  0.822261   0.05064   \n",
              "306  GradientBoostingRegressor  0.688071   0.788019  0.822261   0.05064   \n",
              "270  GradientBoostingRegressor  0.687524    0.78782  0.822032   0.05083   \n",
              "297  GradientBoostingRegressor  0.687524    0.78782  0.822032   0.05083   \n",
              "..                         ...       ...        ...       ...       ...   \n",
              "564  GradientBoostingRegressor -0.033214   0.067398  0.141992  0.071831   \n",
              "699  GradientBoostingRegressor -0.033214   0.067398  0.141992  0.071831   \n",
              "555  GradientBoostingRegressor -0.033214   0.067398  0.141992  0.071831   \n",
              "546  GradientBoostingRegressor -0.033214   0.067398  0.141992  0.071831   \n",
              "510  GradientBoostingRegressor -0.033214   0.067398  0.141992  0.071831   \n",
              "\n",
              "    model__learning_rate model__max_depth model__min_impurity_decrease  \\\n",
              "279                 0.01                3                            3   \n",
              "252                 0.01                3                            0   \n",
              "306                 0.01                3                           10   \n",
              "270                 0.01                3                            3   \n",
              "297                 0.01                3                           10   \n",
              "..                   ...              ...                          ...   \n",
              "564                0.001                3                           10   \n",
              "699                0.001             None                            3   \n",
              "555                0.001                3                           10   \n",
              "546                0.001                3                           10   \n",
              "510                0.001                3                            0   \n",
              "\n",
              "    model__min_samples_split model__min_weight_fraction_leaf  \\\n",
              "279                        3                             0.0   \n",
              "252                        3                             0.0   \n",
              "306                        3                             0.0   \n",
              "270                        2                             0.0   \n",
              "297                        2                             0.0   \n",
              "..                       ...                             ...   \n",
              "564                        5                             0.5   \n",
              "699                        5                             0.5   \n",
              "555                        3                             0.5   \n",
              "546                        2                             0.5   \n",
              "510                        5                             0.5   \n",
              "\n",
              "    model__n_estimators  \n",
              "279                 400  \n",
              "252                 400  \n",
              "306                 400  \n",
              "270                 400  \n",
              "297                 400  \n",
              "..                  ...  \n",
              "564                 400  \n",
              "699                 400  \n",
              "555                 400  \n",
              "546                 400  \n",
              "510                 400  \n",
              "\n",
              "[729 rows x 11 columns]"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
        "print(grid_search_summary.shape)\n",
        "grid_search_summary "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We can see that GradientBoostingRegressor provides us with the best mean score.\n",
        "* The R2 score of 0.77 is sufficient to meet the performance goal of our model as per our client's business case.\n",
        "* Next we will try find the best hyperparameters for our model and try to fine tune it so that we can improve it's score on our TrainSet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "models_search = {\n",
        "    \"GradientBoostingRegressor\":GradientBoostingRegressor(random_state=0),\n",
        "}\n",
        "\n",
        "params_search = {\n",
        "    \"GradientBoostingRegressor\":{\n",
        "        'model__n_estimators': [400,450,500],\n",
        "        'model__learning_rate': [1e-1,1e-2,1e-3], \n",
        "        'model__max_depth': [3,10,None],\n",
        "        'model__min_samples_split': [2,3,5],\n",
        "        'model__min_weight_fraction_leaf':[0.0, 0.3, 0.5],\n",
        "        'model__min_impurity_decrease': [0, 3, 10]\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We perform another Cross Validation search using only \"GradientBoostingRegressor\" as our model and a set of hyperparameters to apply, in order to find the best hyperparameter permutation for our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running GridSearchCV for GradientBoostingRegressor \n",
            "\n",
            "Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n"
          ]
        }
      ],
      "source": [
        "warnings.filterwarnings('ignore')\n",
        "search = HyperparameterOptimizationSearch(models=models_search, params=params_search)\n",
        "search.fit(X_train, y_train, scoring = 'r2', n_jobs=-1, cv=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We add the results to a DataFrame and assess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>estimator</th>\n",
              "      <th>min_score</th>\n",
              "      <th>mean_score</th>\n",
              "      <th>max_score</th>\n",
              "      <th>std_score</th>\n",
              "      <th>model__learning_rate</th>\n",
              "      <th>model__max_depth</th>\n",
              "      <th>model__min_impurity_decrease</th>\n",
              "      <th>model__min_samples_split</th>\n",
              "      <th>model__min_weight_fraction_leaf</th>\n",
              "      <th>model__n_estimators</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>279</th>\n",
              "      <td>GradientBoostingRegressor</td>\n",
              "      <td>0.688071</td>\n",
              "      <td>0.788019</td>\n",
              "      <td>0.822261</td>\n",
              "      <td>0.05064</td>\n",
              "      <td>0.01</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>252</th>\n",
              "      <td>GradientBoostingRegressor</td>\n",
              "      <td>0.688071</td>\n",
              "      <td>0.788019</td>\n",
              "      <td>0.822261</td>\n",
              "      <td>0.05064</td>\n",
              "      <td>0.01</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>306</th>\n",
              "      <td>GradientBoostingRegressor</td>\n",
              "      <td>0.688071</td>\n",
              "      <td>0.788019</td>\n",
              "      <td>0.822261</td>\n",
              "      <td>0.05064</td>\n",
              "      <td>0.01</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270</th>\n",
              "      <td>GradientBoostingRegressor</td>\n",
              "      <td>0.687524</td>\n",
              "      <td>0.78782</td>\n",
              "      <td>0.822032</td>\n",
              "      <td>0.05083</td>\n",
              "      <td>0.01</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>297</th>\n",
              "      <td>GradientBoostingRegressor</td>\n",
              "      <td>0.687524</td>\n",
              "      <td>0.78782</td>\n",
              "      <td>0.822032</td>\n",
              "      <td>0.05083</td>\n",
              "      <td>0.01</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>GradientBoostingRegressor</td>\n",
              "      <td>-0.033214</td>\n",
              "      <td>0.067398</td>\n",
              "      <td>0.141992</td>\n",
              "      <td>0.071831</td>\n",
              "      <td>0.001</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>699</th>\n",
              "      <td>GradientBoostingRegressor</td>\n",
              "      <td>-0.033214</td>\n",
              "      <td>0.067398</td>\n",
              "      <td>0.141992</td>\n",
              "      <td>0.071831</td>\n",
              "      <td>0.001</td>\n",
              "      <td>None</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>555</th>\n",
              "      <td>GradientBoostingRegressor</td>\n",
              "      <td>-0.033214</td>\n",
              "      <td>0.067398</td>\n",
              "      <td>0.141992</td>\n",
              "      <td>0.071831</td>\n",
              "      <td>0.001</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "      <td>0.5</td>\n",
              "      <td>400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>546</th>\n",
              "      <td>GradientBoostingRegressor</td>\n",
              "      <td>-0.033214</td>\n",
              "      <td>0.067398</td>\n",
              "      <td>0.141992</td>\n",
              "      <td>0.071831</td>\n",
              "      <td>0.001</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>0.5</td>\n",
              "      <td>400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>510</th>\n",
              "      <td>GradientBoostingRegressor</td>\n",
              "      <td>-0.033214</td>\n",
              "      <td>0.067398</td>\n",
              "      <td>0.141992</td>\n",
              "      <td>0.071831</td>\n",
              "      <td>0.001</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0.5</td>\n",
              "      <td>400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>729 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                     estimator min_score mean_score max_score std_score  \\\n",
              "279  GradientBoostingRegressor  0.688071   0.788019  0.822261   0.05064   \n",
              "252  GradientBoostingRegressor  0.688071   0.788019  0.822261   0.05064   \n",
              "306  GradientBoostingRegressor  0.688071   0.788019  0.822261   0.05064   \n",
              "270  GradientBoostingRegressor  0.687524    0.78782  0.822032   0.05083   \n",
              "297  GradientBoostingRegressor  0.687524    0.78782  0.822032   0.05083   \n",
              "..                         ...       ...        ...       ...       ...   \n",
              "564  GradientBoostingRegressor -0.033214   0.067398  0.141992  0.071831   \n",
              "699  GradientBoostingRegressor -0.033214   0.067398  0.141992  0.071831   \n",
              "555  GradientBoostingRegressor -0.033214   0.067398  0.141992  0.071831   \n",
              "546  GradientBoostingRegressor -0.033214   0.067398  0.141992  0.071831   \n",
              "510  GradientBoostingRegressor -0.033214   0.067398  0.141992  0.071831   \n",
              "\n",
              "    model__learning_rate model__max_depth model__min_impurity_decrease  \\\n",
              "279                 0.01                3                            3   \n",
              "252                 0.01                3                            0   \n",
              "306                 0.01                3                           10   \n",
              "270                 0.01                3                            3   \n",
              "297                 0.01                3                           10   \n",
              "..                   ...              ...                          ...   \n",
              "564                0.001                3                           10   \n",
              "699                0.001             None                            3   \n",
              "555                0.001                3                           10   \n",
              "546                0.001                3                           10   \n",
              "510                0.001                3                            0   \n",
              "\n",
              "    model__min_samples_split model__min_weight_fraction_leaf  \\\n",
              "279                        3                             0.0   \n",
              "252                        3                             0.0   \n",
              "306                        3                             0.0   \n",
              "270                        2                             0.0   \n",
              "297                        2                             0.0   \n",
              "..                       ...                             ...   \n",
              "564                        5                             0.5   \n",
              "699                        5                             0.5   \n",
              "555                        3                             0.5   \n",
              "546                        2                             0.5   \n",
              "510                        5                             0.5   \n",
              "\n",
              "    model__n_estimators  \n",
              "279                 400  \n",
              "252                 400  \n",
              "306                 400  \n",
              "270                 400  \n",
              "297                 400  \n",
              "..                  ...  \n",
              "564                 400  \n",
              "699                 400  \n",
              "555                 400  \n",
              "546                 400  \n",
              "510                 400  \n",
              "\n",
              "[729 rows x 11 columns]"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
        "grid_search_summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We can see that we have an improvement in the mean R2 score, bringing it up to -----insert score----\n",
        "* We will use these hyperparameters for our model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We print our best model below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'GradientBoostingRegressor'"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_model = grid_search_summary.iloc[0,0]\n",
        "best_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We print our best combination of hyperparameters for our algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'model__learning_rate': 0.01,\n",
              " 'model__max_depth': 3,\n",
              " 'model__min_impurity_decrease': 0,\n",
              " 'model__min_samples_split': 3,\n",
              " 'model__min_weight_fraction_leaf': 0.0,\n",
              " 'model__n_estimators': 400}"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_hyperparams = grid_search_pipelines[best_model].best_params_\n",
        "best_hyperparams"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We define our best pipeline at this stage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Pipeline(steps=[('scaler', StandardScaler()),\n",
              "                ('feat_selection',\n",
              "                 SelectFromModel(estimator=GradientBoostingRegressor(random_state=0))),\n",
              "                ('model',\n",
              "                 GradientBoostingRegressor(learning_rate=0.01,\n",
              "                                           min_impurity_decrease=0,\n",
              "                                           min_samples_split=3,\n",
              "                                           n_estimators=400, random_state=0))])"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipeline_clf = grid_search_pipelines[best_model].best_estimator_\n",
        "pipeline_clf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Push files to Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* In case you don't need to push files to Repo, you may replace this section for \"Conclusions and Next Steps\" and state your conclusions and next steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKlnIozA4eQO",
        "outputId": "fd09bc1f-adb1-4511-f6ce-492a6af570c0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "try:\n",
        "  # create here your folder\n",
        "  # os.makedirs(name='')\n",
        "except Exception as e:\n",
        "  print(e)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
