{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **(ADD HERE THE NOTEBOOK NAME)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Write here your notebook objective, for example, \"Fetch data from Kaggle and save as raw data\", or \"engineer features for modelling\"\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* Write here which data or information you need to run the notebook \n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Write here which files, code or artifacts you generate by the end of the notebook \n",
        "\n",
        "## CRISP-DM\n",
        "\n",
        "* Modelling\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We are assuming you will store the notebooks in a sub folder, therefore when running the notebook in the editor, you will need to change the working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/workspace/milestone-project-heritage-housing-issues/jupyter_notebooks'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You set a new current directory\n"
          ]
        }
      ],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/workspace/milestone-project-heritage-housing-issues'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1460, 22)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1stFlrSF</th>\n",
              "      <th>2ndFlrSF</th>\n",
              "      <th>BedroomAbvGr</th>\n",
              "      <th>BsmtExposure</th>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <th>BsmtFinType1</th>\n",
              "      <th>BsmtUnfSF</th>\n",
              "      <th>GarageArea</th>\n",
              "      <th>GarageFinish</th>\n",
              "      <th>GarageYrBlt</th>\n",
              "      <th>...</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>MasVnrArea</th>\n",
              "      <th>OpenPorchSF</th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>TotalBsmtSF</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YearRemodAdd</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>856</td>\n",
              "      <td>854.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>No</td>\n",
              "      <td>706</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>150</td>\n",
              "      <td>548</td>\n",
              "      <td>RFn</td>\n",
              "      <td>2003.0</td>\n",
              "      <td>...</td>\n",
              "      <td>8450</td>\n",
              "      <td>65.0</td>\n",
              "      <td>196.0</td>\n",
              "      <td>61</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>856</td>\n",
              "      <td>2003</td>\n",
              "      <td>2003</td>\n",
              "      <td>208500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1262</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Gd</td>\n",
              "      <td>978</td>\n",
              "      <td>ALQ</td>\n",
              "      <td>284</td>\n",
              "      <td>460</td>\n",
              "      <td>RFn</td>\n",
              "      <td>1976.0</td>\n",
              "      <td>...</td>\n",
              "      <td>9600</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>1262</td>\n",
              "      <td>1976</td>\n",
              "      <td>1976</td>\n",
              "      <td>181500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>920</td>\n",
              "      <td>866.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Mn</td>\n",
              "      <td>486</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>434</td>\n",
              "      <td>608</td>\n",
              "      <td>RFn</td>\n",
              "      <td>2001.0</td>\n",
              "      <td>...</td>\n",
              "      <td>11250</td>\n",
              "      <td>68.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>42</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>920</td>\n",
              "      <td>2001</td>\n",
              "      <td>2002</td>\n",
              "      <td>223500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>961</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>No</td>\n",
              "      <td>216</td>\n",
              "      <td>ALQ</td>\n",
              "      <td>540</td>\n",
              "      <td>642</td>\n",
              "      <td>Unf</td>\n",
              "      <td>1998.0</td>\n",
              "      <td>...</td>\n",
              "      <td>9550</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>35</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>756</td>\n",
              "      <td>1915</td>\n",
              "      <td>1970</td>\n",
              "      <td>140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1145</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Av</td>\n",
              "      <td>655</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>490</td>\n",
              "      <td>836</td>\n",
              "      <td>RFn</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>...</td>\n",
              "      <td>14260</td>\n",
              "      <td>84.0</td>\n",
              "      <td>350.0</td>\n",
              "      <td>84</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>1145</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>250000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 22 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   1stFlrSF  2ndFlrSF  BedroomAbvGr BsmtExposure  BsmtFinSF1 BsmtFinType1  \\\n",
              "0       856     854.0           3.0           No         706          GLQ   \n",
              "1      1262       0.0           3.0           Gd         978          ALQ   \n",
              "2       920     866.0           3.0           Mn         486          GLQ   \n",
              "3       961       NaN           NaN           No         216          ALQ   \n",
              "4      1145       NaN           4.0           Av         655          GLQ   \n",
              "\n",
              "   BsmtUnfSF  GarageArea GarageFinish  GarageYrBlt  ...  LotArea LotFrontage  \\\n",
              "0        150         548          RFn       2003.0  ...     8450        65.0   \n",
              "1        284         460          RFn       1976.0  ...     9600        80.0   \n",
              "2        434         608          RFn       2001.0  ...    11250        68.0   \n",
              "3        540         642          Unf       1998.0  ...     9550        60.0   \n",
              "4        490         836          RFn       2000.0  ...    14260        84.0   \n",
              "\n",
              "   MasVnrArea  OpenPorchSF  OverallCond  OverallQual  TotalBsmtSF  YearBuilt  \\\n",
              "0       196.0           61            5            7          856       2003   \n",
              "1         0.0            0            8            6         1262       1976   \n",
              "2       162.0           42            5            7          920       2001   \n",
              "3         0.0           35            5            7          756       1915   \n",
              "4       350.0           84            5            8         1145       2000   \n",
              "\n",
              "   YearRemodAdd  SalePrice  \n",
              "0          2003     208500  \n",
              "1          1976     181500  \n",
              "2          2002     223500  \n",
              "3          1970     140000  \n",
              "4          2000     250000  \n",
              "\n",
              "[5 rows x 22 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = (pd.read_csv(f\"inputs/datasets/unzipped/house_prices_records.csv\")\n",
        "        .drop(labels=['EnclosedPorch', 'WoodDeckSF'],axis=1))\n",
        "print(df.shape)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "arbitrary_imputation_vars = ['2ndFlrSF']\n",
        "median_imputation_vars = ['BedroomAbvGr', 'LotFrontage','GarageYrBlt','MasVnrArea']\n",
        "most_frequent_vars = ['BsmtFinType1']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['BsmtExposure', 'BsmtFinType1', 'GarageFinish', 'KitchenQual']"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "categorical_encoding_vars =df.select_dtypes(include=['object']).columns.to_list()\n",
        "categorical_encoding_vars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "log_transformation_vars = ['1stFlrSF', 'LotArea']\n",
        "yeojohnson_vars = ['GrLivArea']\n",
        "boxcox_vars =[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['1stFlrSF',\n",
              " '2ndFlrSF',\n",
              " 'BedroomAbvGr',\n",
              " 'BsmtExposure',\n",
              " 'BsmtFinSF1',\n",
              " 'BsmtFinType1',\n",
              " 'BsmtUnfSF',\n",
              " 'GarageArea',\n",
              " 'GarageFinish',\n",
              " 'GarageYrBlt',\n",
              " 'GrLivArea',\n",
              " 'KitchenQual',\n",
              " 'LotArea',\n",
              " 'LotFrontage',\n",
              " 'MasVnrArea',\n",
              " 'OpenPorchSF',\n",
              " 'OverallCond',\n",
              " 'OverallQual',\n",
              " 'TotalBsmtSF',\n",
              " 'YearBuilt',\n",
              " 'YearRemodAdd']"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "smart_correlation_features = df.columns.to_list() \n",
        "smart_correlation_features.pop()\n",
        "smart_correlation_features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We Will handle Data cleaning for 'GarageFinish' outside of the pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1460 entries, 0 to 1459\n",
            "Data columns (total 1 columns):\n",
            " #   Column        Non-Null Count  Dtype \n",
            "---  ------        --------------  ----- \n",
            " 0   GarageFinish  1460 non-null   object\n",
            "dtypes: object(1)\n",
            "memory usage: 11.5+ KB\n"
          ]
        }
      ],
      "source": [
        "nan_GarageFinish_vals=df[df['GarageFinish'].isna()]\n",
        "nan_GarageFinish_index = list(nan_GarageFinish_vals.index.values)\n",
        "\n",
        "df['GarageFinish'] = df['GarageFinish'].fillna(0)\n",
        "\n",
        "for x in nan_GarageFinish_index:\n",
        "    garage_area_value = df.iloc[x,8]\n",
        "    if garage_area_value == 0:\n",
        "        df.at[x,'GarageFinish'] = 'None'\n",
        "    else:\n",
        "        df.at[x,'GarageFinish'] = 'Unf'\n",
        "\n",
        "df.filter(['GarageFinish']).info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Create ML Pipelines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Data Cleaning and Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Pipeline(steps=[('ArbitraryImputer',\n",
              "                 ArbitraryNumberImputer(arbitrary_number=0,\n",
              "                                        variables=['2ndFlrSF'])),\n",
              "                ('MedianImputation',\n",
              "                 MeanMedianImputer(variables=['BedroomAbvGr', 'LotFrontage',\n",
              "                                              'GarageYrBlt', 'MasVnrArea'])),\n",
              "                ('CategoricalImputer',\n",
              "                 CategoricalImputer(imputation_method='frequent',\n",
              "                                    variables=['BsmtFinType1'])),\n",
              "                ('OrdinalCategoricalEncoder',\n",
              "                 OrdinalEnco...\n",
              "                 SmartCorrelatedSelection(selection_method='variance',\n",
              "                                          threshold=0.6,\n",
              "                                          variables=['1stFlrSF', '2ndFlrSF',\n",
              "                                                     'BedroomAbvGr',\n",
              "                                                     'BsmtExposure',\n",
              "                                                     'BsmtFinSF1',\n",
              "                                                     'BsmtFinType1',\n",
              "                                                     'BsmtUnfSF', 'GarageArea',\n",
              "                                                     'GarageFinish',\n",
              "                                                     'GarageYrBlt', 'GrLivArea',\n",
              "                                                     'KitchenQual', 'LotArea',\n",
              "                                                     'LotFrontage',\n",
              "                                                     'MasVnrArea',\n",
              "                                                     'OpenPorchSF',\n",
              "                                                     'OverallCond',\n",
              "                                                     'OverallQual',\n",
              "                                                     'TotalBsmtSF', 'YearBuilt',\n",
              "                                                     'YearRemodAdd']))])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "### Data Cleaning\n",
        "from feature_engine.imputation import MeanMedianImputer\n",
        "from feature_engine.imputation import ArbitraryNumberImputer\n",
        "from feature_engine.imputation import CategoricalImputer\n",
        "\n",
        "### Feature Engineering\n",
        "from feature_engine.selection import SmartCorrelatedSelection\n",
        "from feature_engine.encoding import OrdinalEncoder\n",
        "from feature_engine import transformation as vt\n",
        "\n",
        "def PipelineDataCleaningAndFeatureEngineering():\n",
        "  pipeline_base = Pipeline([\n",
        "    (\"ArbitraryImputer\", ArbitraryNumberImputer(arbitrary_number=0,\n",
        "                                            variables=arbitrary_imputation_vars)),\n",
        "                                \n",
        "    (\"MedianImputation\", MeanMedianImputer(imputation_method='median',\n",
        "                                            variables=median_imputation_vars)),\n",
        "    \n",
        "    (\"CategoricalImputer\", CategoricalImputer(imputation_method='frequent', \n",
        "                                        variables=most_frequent_vars)),\n",
        "\n",
        "    (\"OrdinalCategoricalEncoder\",OrdinalEncoder(encoding_method='arbitrary', \n",
        "                                                variables = categorical_encoding_vars)),\n",
        "    \n",
        "    (\"LogTransformer\", vt.YeoJohnsonTransformer(variables = yeojohnson_vars)),\n",
        "\n",
        "    (\"YeoJohnsonTransformer\", vt.YeoJohnsonTransformer(variables = yeojohnson_vars)),\n",
        "\n",
        "    # (\"BoxCoxTransformer\", vt.BoxCoxTransformer(variables = boxcox_vars)),\n",
        "      \n",
        "    (\"SmartCorrelatedSelection\",SmartCorrelatedSelection(variables=smart_correlation_features, \n",
        "                                                          method=\"pearson\", threshold=0.6, \n",
        "                                                          selection_method=\"variance\") ),\n",
        "       \n",
        "  ])\n",
        "\n",
        "  return pipeline_base\n",
        "\n",
        "PipelineDataCleaningAndFeatureEngineering()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "# ML Pipeline for Modelling and Hyperparameter Optimization\n",
        "\n",
        "* Our next step is choosing the optimal algorithm for our ML model and the most effective hyperparameter for our selected algorithm\n",
        "* We will do so with the below function and custom class.\n",
        "    * Below code taken from CI lesson: *Scikit-Learn Unit 6: Cross Validation Search Part 2*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "### Feat Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "### Feat Selection\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "### ML algorithms \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import LinearRegression \n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier \n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "def PipelineClf(model):\n",
        "  pipeline_base = Pipeline([\n",
        "       (\"scaler\",StandardScaler() ),\n",
        "       (\"feat_selection\",SelectFromModel(model) ),\n",
        "       (\"model\",model ),\n",
        "  ])\n",
        "\n",
        "  return pipeline_base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "class HyperparameterOptimizationSearch:\n",
        "\n",
        "    def __init__(self, models, params):\n",
        "        self.models = models\n",
        "        self.params = params\n",
        "        self.keys = models.keys()\n",
        "        self.grid_searches = {}\n",
        "\n",
        "    def fit(self, X, y, cv, n_jobs, verbose=1, scoring=None, refit=False):\n",
        "        for key in self.keys:\n",
        "            print(f\"\\nRunning GridSearchCV for {key} \\n\")\n",
        "\n",
        "            model =  PipelineClf(self.models[key])\n",
        "            params = self.params[key]\n",
        "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs, verbose=verbose, scoring=scoring, )\n",
        "            gs.fit(X,y)\n",
        "            self.grid_searches[key] = gs    \n",
        "\n",
        "    def score_summary(self, sort_by='mean_score'):\n",
        "        def row(key, scores, params):\n",
        "            d = {\n",
        "                 'estimator': key,\n",
        "                 'min_score': min(scores),\n",
        "                 'max_score': max(scores),\n",
        "                 'mean_score': np.mean(scores),\n",
        "                 'std_score': np.std(scores),\n",
        "            }\n",
        "            return pd.Series({**params,**d})\n",
        "\n",
        "        rows = []\n",
        "        for k in self.grid_searches:\n",
        "            params = self.grid_searches[k].cv_results_['params']\n",
        "            scores = []\n",
        "            for i in range(self.grid_searches[k].cv):\n",
        "                key = \"split{}_test_score\".format(i)\n",
        "                r = self.grid_searches[k].cv_results_[key]        \n",
        "                scores.append(r.reshape(len(params),1))\n",
        "\n",
        "            all_scores = np.hstack(scores)\n",
        "            for p, s in zip(params,all_scores):\n",
        "                rows.append((row(k, s, p)))\n",
        "\n",
        "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
        "        columns = ['estimator', 'min_score', 'mean_score', 'max_score', 'std_score']\n",
        "        columns = columns + [c for c in df.columns if c not in columns]\n",
        "        return df[columns], self.grid_searches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Split Train & Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1168, 21) (1168,) (292, 21) (292,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test,y_train, y_test = train_test_split(\n",
        "                                    df.drop(['SalePrice'],axis=1),\n",
        "                                    df['SalePrice'],\n",
        "                                    test_size = 0.2,\n",
        "                                    random_state = 0,\n",
        "                                    )\n",
        "\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We apply our first pipeline to our train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "\"['GarageYrBlt'] not in index\"",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [17], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m make_scorer, r2_score\n\u001b[1;32m      3\u001b[0m pipeline_data_cleaning_feat_eng \u001b[39m=\u001b[39m PipelineDataCleaningAndFeatureEngineering()\n\u001b[0;32m----> 4\u001b[0m X_train \u001b[39m=\u001b[39m pipeline_data_cleaning_feat_eng\u001b[39m.\u001b[39;49mfit_transform(X_train)\n\u001b[1;32m      5\u001b[0m X_test \u001b[39m=\u001b[39m pipeline_data_cleaning_feat_eng\u001b[39m.\u001b[39mtransform(X_test)\n\u001b[1;32m      6\u001b[0m \u001b[39mprint\u001b[39m(X_train\u001b[39m.\u001b[39mshape, y_train\u001b[39m.\u001b[39mshape, X_test\u001b[39m.\u001b[39mshape, y_test\u001b[39m.\u001b[39mshape)\n",
            "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/pipeline.py:378\u001b[0m, in \u001b[0;36mPipeline.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[39m\"\"\"Fit the model and transform with the final estimator\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \n\u001b[1;32m    353\u001b[0m \u001b[39mFits all the transforms one after the other and transforms the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[39m    Transformed samples\u001b[39;00m\n\u001b[1;32m    376\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    377\u001b[0m fit_params_steps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_fit_params(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m--> 378\u001b[0m Xt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_steps)\n\u001b[1;32m    380\u001b[0m last_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator\n\u001b[1;32m    381\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(\u001b[39m'\u001b[39m\u001b[39mPipeline\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m    382\u001b[0m                          \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_message(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)):\n",
            "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/pipeline.py:303\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    301\u001b[0m     cloned_transformer \u001b[39m=\u001b[39m clone(transformer)\n\u001b[1;32m    302\u001b[0m \u001b[39m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[0;32m--> 303\u001b[0m X, fitted_transformer \u001b[39m=\u001b[39m fit_transform_one_cached(\n\u001b[1;32m    304\u001b[0m     cloned_transformer, X, y, \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    305\u001b[0m     message_clsname\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mPipeline\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m    306\u001b[0m     message\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_log_message(step_idx),\n\u001b[1;32m    307\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_steps[name])\n\u001b[1;32m    308\u001b[0m \u001b[39m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[39m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \u001b[39m# from the cache.\u001b[39;00m\n\u001b[1;32m    311\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[step_idx] \u001b[39m=\u001b[39m (name, fitted_transformer)\n",
            "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/joblib/memory.py:352\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 352\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/pipeline.py:754\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    752\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[1;32m    753\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(transformer, \u001b[39m'\u001b[39m\u001b[39mfit_transform\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m--> 754\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39;49mfit_transform(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    755\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    756\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
            "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/sklearn/base.py:699\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    695\u001b[0m \u001b[39m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[1;32m    696\u001b[0m \u001b[39m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[1;32m    697\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    698\u001b[0m     \u001b[39m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[0;32m--> 699\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[1;32m    700\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    701\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m    702\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
            "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/feature_engine/imputation/mean_median.py:96\u001b[0m, in \u001b[0;36mMeanMedianImputer.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     93\u001b[0m X \u001b[39m=\u001b[39m _is_dataframe(X)\n\u001b[1;32m     95\u001b[0m \u001b[39m# find or check for numerical variables\u001b[39;00m\n\u001b[0;32m---> 96\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvariables \u001b[39m=\u001b[39m _find_or_check_numerical_variables(X, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvariables)\n\u001b[1;32m     98\u001b[0m \u001b[39m# find imputation parameters: mean or median\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimputation_method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m\"\u001b[39m:\n",
            "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/feature_engine/variable_manipulation.py:76\u001b[0m, in \u001b[0;36m_find_or_check_numerical_variables\u001b[0;34m(X, variables)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     70\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mNo numerical variables in this dataframe. Please check variable\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     71\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mformat with pandas dtypes\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     72\u001b[0m         )\n\u001b[1;32m     74\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     75\u001b[0m     \u001b[39m# check that user entered variables are of type numerical\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39many\u001b[39m(X[variables]\u001b[39m.\u001b[39mselect_dtypes(exclude\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnumber\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mcolumns):\n\u001b[1;32m     77\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m     78\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mSome of the variables are not numerical. Please cast them as \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     79\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mnumerical before using this transformer\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     80\u001b[0m         )\n\u001b[1;32m     82\u001b[0m \u001b[39mreturn\u001b[39;00m variables\n",
            "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/pandas/core/frame.py:3511\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3509\u001b[0m     \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3510\u001b[0m         key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n\u001b[0;32m-> 3511\u001b[0m     indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49m_get_indexer_strict(key, \u001b[39m\"\u001b[39;49m\u001b[39mcolumns\u001b[39;49m\u001b[39m\"\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[1;32m   3513\u001b[0m \u001b[39m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3514\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n",
            "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/pandas/core/indexes/base.py:5782\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5779\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   5780\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 5782\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   5784\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[1;32m   5785\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[1;32m   5786\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
            "File \u001b[0;32m/workspace/.pip-modules/lib/python3.8/site-packages/pandas/core/indexes/base.py:5845\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5842\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   5844\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[0;32m-> 5845\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['GarageYrBlt'] not in index\""
          ]
        }
      ],
      "source": [
        "pipeline_data_cleaning_feat_eng = PipelineDataCleaningAndFeatureEngineering()\n",
        "X_train = pipeline_data_cleaning_feat_eng.fit_transform(X_train)\n",
        "X_test = pipeline_data_cleaning_feat_eng.transform(X_test)\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Scikit Learn Cross Validation Search\n",
        "\n",
        "* We first search for the most suitable algorithm using tandard hyper parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "models_quick_search = {\n",
        "    \"LogisticRegression\": LogisticRegression(random_state=0),\n",
        "    \"LinearRegression\": LinearRegression(),\n",
        "    \"GradientBoostingRegressor\": GradientBoostingRegressor(random_state=0), \n",
        "    \"XGBClassifier\":XGBClassifier(random_state=0),\n",
        "    \"DecisionTreeClassifier\":DecisionTreeClassifier(random_state=0),\n",
        "    \"RandomForestClassifier\":RandomForestClassifier(random_state=0),\n",
        "    \"GradientBoostingClassifier\":GradientBoostingClassifier(random_state=0),\n",
        "    \"ExtraTreesClassifier\":ExtraTreesClassifier(random_state=0),\n",
        "    \"AdaBoostClassifier\":AdaBoostClassifier(random_state=0),\n",
        "}\n",
        "\n",
        "params_quick_search = {\n",
        "    \"LogisticRegression\":{},\n",
        "    \"LinearRegression\": {},\n",
        "    \"GradientBoostingRegressor\": {},\n",
        "    \"XGBClassifier\":{},\n",
        "    \"DecisionTreeClassifier\":{},\n",
        "    \"RandomForestClassifier\":{},\n",
        "    \"GradientBoostingClassifier\":{},\n",
        "    \"ExtraTreesClassifier\":{},\n",
        "    \"AdaBoostClassifier\":{},\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running GridSearchCV for LogisticRegression \n",
            "\n",
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
            "\n",
            "Running GridSearchCV for LinearRegression \n",
            "\n",
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
            "\n",
            "Running GridSearchCV for GradientBoostingRegressor \n",
            "\n",
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
            "\n",
            "Running GridSearchCV for XGBClassifier \n",
            "\n",
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/workspace/.pip-modules/lib/python3.8/site-packages/xgboost/compat.py:93: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
            "  from pandas import MultiIndex, Int64Index\n",
            "/workspace/.pip-modules/lib/python3.8/site-packages/xgboost/compat.py:93: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
            "  from pandas import MultiIndex, Int64Index\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running GridSearchCV for DecisionTreeClassifier \n",
            "\n",
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
            "\n",
            "Running GridSearchCV for RandomForestClassifier \n",
            "\n",
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
            "\n",
            "Running GridSearchCV for GradientBoostingClassifier \n",
            "\n",
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
            "\n",
            "Running GridSearchCV for ExtraTreesClassifier \n",
            "\n",
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
            "\n",
            "Running GridSearchCV for AdaBoostClassifier \n",
            "\n",
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import make_scorer, r2_score\n",
        "search = HyperparameterOptimizationSearch(models=models_quick_search, params=params_quick_search)\n",
        "search.fit(X_train, y_train, \n",
        "            scoring=make_scorer(r2_score), n_jobs=-1, cv=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We assess the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>estimator</th>\n",
              "      <th>min_score</th>\n",
              "      <th>mean_score</th>\n",
              "      <th>max_score</th>\n",
              "      <th>std_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>LinearRegression</td>\n",
              "      <td>0.751548</td>\n",
              "      <td>0.770833</td>\n",
              "      <td>0.790118</td>\n",
              "      <td>0.019285</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>GradientBoostingRegressor</td>\n",
              "      <td>0.739127</td>\n",
              "      <td>0.750045</td>\n",
              "      <td>0.760963</td>\n",
              "      <td>0.010918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>0.504332</td>\n",
              "      <td>0.54885</td>\n",
              "      <td>0.593368</td>\n",
              "      <td>0.044518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>RandomForestClassifier</td>\n",
              "      <td>0.503551</td>\n",
              "      <td>0.51888</td>\n",
              "      <td>0.534208</td>\n",
              "      <td>0.015329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ExtraTreesClassifier</td>\n",
              "      <td>0.491668</td>\n",
              "      <td>0.517517</td>\n",
              "      <td>0.543365</td>\n",
              "      <td>0.025849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>XGBClassifier</td>\n",
              "      <td>0.315764</td>\n",
              "      <td>0.328087</td>\n",
              "      <td>0.340409</td>\n",
              "      <td>0.012323</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>DecisionTreeClassifier</td>\n",
              "      <td>0.317078</td>\n",
              "      <td>0.327914</td>\n",
              "      <td>0.33875</td>\n",
              "      <td>0.010836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>0.098439</td>\n",
              "      <td>0.152071</td>\n",
              "      <td>0.205703</td>\n",
              "      <td>0.053632</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>AdaBoostClassifier</td>\n",
              "      <td>-0.300417</td>\n",
              "      <td>-0.076815</td>\n",
              "      <td>0.146786</td>\n",
              "      <td>0.223602</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    estimator min_score mean_score max_score std_score\n",
              "1            LinearRegression  0.751548   0.770833  0.790118  0.019285\n",
              "2   GradientBoostingRegressor  0.739127   0.750045  0.760963  0.010918\n",
              "0          LogisticRegression  0.504332    0.54885  0.593368  0.044518\n",
              "5      RandomForestClassifier  0.503551    0.51888  0.534208  0.015329\n",
              "7        ExtraTreesClassifier  0.491668   0.517517  0.543365  0.025849\n",
              "3               XGBClassifier  0.315764   0.328087  0.340409  0.012323\n",
              "4      DecisionTreeClassifier  0.317078   0.327914   0.33875  0.010836\n",
              "6  GradientBoostingClassifier  0.098439   0.152071  0.205703  0.053632\n",
              "8          AdaBoostClassifier -0.300417  -0.076815  0.146786  0.223602"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
        "grid_search_summary "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "NOTE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* You may add how many sections you want, as long as it supports your project workflow.\n",
        "* All notebook's cells should be run top-down (you can't create a dynamic wherein a given point you need to go back to a previous cell to execute some task, like go back to a previous cell and refresh a variable content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Push files to Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* In case you don't need to push files to Repo, you may replace this section for \"Conclusions and Next Steps\" and state your conclusions and next steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKlnIozA4eQO",
        "outputId": "fd09bc1f-adb1-4511-f6ce-492a6af570c0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "try:\n",
        "  # create here your folder\n",
        "  # os.makedirs(name='')\n",
        "except Exception as e:\n",
        "  print(e)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
