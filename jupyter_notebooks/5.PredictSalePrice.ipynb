{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **(ADD HERE THE NOTEBOOK NAME)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Write here your notebook objective, for example, \"Fetch data from Kaggle and save as raw data\", or \"engineer features for modelling\"\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* Write here which data or information you need to run the notebook \n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Write here which files, code or artifacts you generate by the end of the notebook \n",
        "\n",
        "## CRISP-DM\n",
        "\n",
        "* Modelling\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We are assuming you will store the notebooks in a sub folder, therefore when running the notebook in the editor, you will need to change the working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/workspace/milestone-project-heritage-housing-issues/jupyter_notebooks'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You set a new current directory\n"
          ]
        }
      ],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/workspace/milestone-project-heritage-housing-issues'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1460, 22)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1stFlrSF</th>\n",
              "      <th>2ndFlrSF</th>\n",
              "      <th>BedroomAbvGr</th>\n",
              "      <th>BsmtExposure</th>\n",
              "      <th>BsmtFinSF1</th>\n",
              "      <th>BsmtFinType1</th>\n",
              "      <th>BsmtUnfSF</th>\n",
              "      <th>GarageArea</th>\n",
              "      <th>GarageFinish</th>\n",
              "      <th>GarageYrBlt</th>\n",
              "      <th>...</th>\n",
              "      <th>LotArea</th>\n",
              "      <th>LotFrontage</th>\n",
              "      <th>MasVnrArea</th>\n",
              "      <th>OpenPorchSF</th>\n",
              "      <th>OverallCond</th>\n",
              "      <th>OverallQual</th>\n",
              "      <th>TotalBsmtSF</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YearRemodAdd</th>\n",
              "      <th>SalePrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>856</td>\n",
              "      <td>854.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>No</td>\n",
              "      <td>706</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>150</td>\n",
              "      <td>548</td>\n",
              "      <td>RFn</td>\n",
              "      <td>2003.0</td>\n",
              "      <td>...</td>\n",
              "      <td>8450</td>\n",
              "      <td>65.0</td>\n",
              "      <td>196.0</td>\n",
              "      <td>61</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>856</td>\n",
              "      <td>2003</td>\n",
              "      <td>2003</td>\n",
              "      <td>208500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1262</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Gd</td>\n",
              "      <td>978</td>\n",
              "      <td>ALQ</td>\n",
              "      <td>284</td>\n",
              "      <td>460</td>\n",
              "      <td>RFn</td>\n",
              "      <td>1976.0</td>\n",
              "      <td>...</td>\n",
              "      <td>9600</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>1262</td>\n",
              "      <td>1976</td>\n",
              "      <td>1976</td>\n",
              "      <td>181500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>920</td>\n",
              "      <td>866.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Mn</td>\n",
              "      <td>486</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>434</td>\n",
              "      <td>608</td>\n",
              "      <td>RFn</td>\n",
              "      <td>2001.0</td>\n",
              "      <td>...</td>\n",
              "      <td>11250</td>\n",
              "      <td>68.0</td>\n",
              "      <td>162.0</td>\n",
              "      <td>42</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>920</td>\n",
              "      <td>2001</td>\n",
              "      <td>2002</td>\n",
              "      <td>223500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>961</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>No</td>\n",
              "      <td>216</td>\n",
              "      <td>ALQ</td>\n",
              "      <td>540</td>\n",
              "      <td>642</td>\n",
              "      <td>Unf</td>\n",
              "      <td>1998.0</td>\n",
              "      <td>...</td>\n",
              "      <td>9550</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>35</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>756</td>\n",
              "      <td>1915</td>\n",
              "      <td>1970</td>\n",
              "      <td>140000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1145</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Av</td>\n",
              "      <td>655</td>\n",
              "      <td>GLQ</td>\n",
              "      <td>490</td>\n",
              "      <td>836</td>\n",
              "      <td>RFn</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>...</td>\n",
              "      <td>14260</td>\n",
              "      <td>84.0</td>\n",
              "      <td>350.0</td>\n",
              "      <td>84</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>1145</td>\n",
              "      <td>2000</td>\n",
              "      <td>2000</td>\n",
              "      <td>250000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 22 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   1stFlrSF  2ndFlrSF  BedroomAbvGr BsmtExposure  BsmtFinSF1 BsmtFinType1  \\\n",
              "0       856     854.0           3.0           No         706          GLQ   \n",
              "1      1262       0.0           3.0           Gd         978          ALQ   \n",
              "2       920     866.0           3.0           Mn         486          GLQ   \n",
              "3       961       NaN           NaN           No         216          ALQ   \n",
              "4      1145       NaN           4.0           Av         655          GLQ   \n",
              "\n",
              "   BsmtUnfSF  GarageArea GarageFinish  GarageYrBlt  ...  LotArea LotFrontage  \\\n",
              "0        150         548          RFn       2003.0  ...     8450        65.0   \n",
              "1        284         460          RFn       1976.0  ...     9600        80.0   \n",
              "2        434         608          RFn       2001.0  ...    11250        68.0   \n",
              "3        540         642          Unf       1998.0  ...     9550        60.0   \n",
              "4        490         836          RFn       2000.0  ...    14260        84.0   \n",
              "\n",
              "   MasVnrArea  OpenPorchSF  OverallCond  OverallQual  TotalBsmtSF  YearBuilt  \\\n",
              "0       196.0           61            5            7          856       2003   \n",
              "1         0.0            0            8            6         1262       1976   \n",
              "2       162.0           42            5            7          920       2001   \n",
              "3         0.0           35            5            7          756       1915   \n",
              "4       350.0           84            5            8         1145       2000   \n",
              "\n",
              "   YearRemodAdd  SalePrice  \n",
              "0          2003     208500  \n",
              "1          1976     181500  \n",
              "2          2002     223500  \n",
              "3          1970     140000  \n",
              "4          2000     250000  \n",
              "\n",
              "[5 rows x 22 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = (pd.read_csv(f\"inputs/datasets/unzipped/house_prices_records.csv\")\n",
        "        .drop(labels=['EnclosedPorch', 'WoodDeckSF'],axis=1))\n",
        "print(df.shape)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "arbitrary_imputation_vars = ['2ndFlrSF', 'EnclosedPorch', 'WoodDeckSF']\n",
        "median_imputation_vars = ['BedroomAbvGr', 'LotFrontage','GarageYrBlt','MasVnrArea']\n",
        "most_frequent_vars = ['BsmtFinType1']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['BsmtExposure', 'BsmtFinType1', 'GarageFinish', 'KitchenQual']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "categorical_encoding_vars =df.select_dtypes(include=['object']).columns.to_list()\n",
        "categorical_encoding_vars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "log_transformation_vars = ['1stFlrSF', 'LotArea']\n",
        "yeojohnson_vars = ['GrLivArea']\n",
        "boxcox_vars =['SalePrice']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['1stFlrSF',\n",
              " '2ndFlrSF',\n",
              " 'BedroomAbvGr',\n",
              " 'BsmtExposure',\n",
              " 'BsmtFinSF1',\n",
              " 'BsmtFinType1',\n",
              " 'BsmtUnfSF',\n",
              " 'GarageArea',\n",
              " 'GarageFinish',\n",
              " 'GarageYrBlt',\n",
              " 'GrLivArea',\n",
              " 'KitchenQual',\n",
              " 'LotArea',\n",
              " 'LotFrontage',\n",
              " 'MasVnrArea',\n",
              " 'OpenPorchSF',\n",
              " 'OverallCond',\n",
              " 'OverallQual',\n",
              " 'TotalBsmtSF',\n",
              " 'YearBuilt',\n",
              " 'YearRemodAdd']"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "smart_correlation_features = df.columns.to_list() \n",
        "smart_correlation_features.pop()\n",
        "smart_correlation_features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We Will handle Data cleaning for 'GarageFinish' outside of the pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1460 entries, 0 to 1459\n",
            "Data columns (total 1 columns):\n",
            " #   Column        Non-Null Count  Dtype \n",
            "---  ------        --------------  ----- \n",
            " 0   GarageFinish  1460 non-null   object\n",
            "dtypes: object(1)\n",
            "memory usage: 11.5+ KB\n"
          ]
        }
      ],
      "source": [
        "nan_GarageFinish_vals=df[df['GarageFinish'].isna()]\n",
        "nan_GarageFinish_index = list(nan_GarageFinish_vals.index.values)\n",
        "\n",
        "df['GarageFinish'] = df['GarageFinish'].fillna(0)\n",
        "\n",
        "for x in nan_GarageFinish_index:\n",
        "    garage_area_value = df.iloc[x,8]\n",
        "    if garage_area_value == 0:\n",
        "        df.at[x,'GarageFinish'] = 'None'\n",
        "    else:\n",
        "        df.at[x,'GarageFinish'] = 'Unf'\n",
        "\n",
        "df.filter(['GarageFinish']).info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Create ML Pipelines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Data Cleaning and Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Pipeline(steps=[('ArbitraryImputer',\n",
              "                 ArbitraryNumberImputer(arbitrary_number=0,\n",
              "                                        variables=['2ndFlrSF', 'EnclosedPorch',\n",
              "                                                   'WoodDeckSF'])),\n",
              "                ('MedianImputation',\n",
              "                 MeanMedianImputer(variables=['BedroomAbvGr', 'LotFrontage',\n",
              "                                              'GarageYrBlt', 'MasVnrArea'])),\n",
              "                ('CategoricalImputer',\n",
              "                 CategoricalImputer(imputation_method='frequent',\n",
              "                                    variables=['BsmtFinType1'])),\n",
              "                ('OrdinalCa...\n",
              "                 SmartCorrelatedSelection(selection_method='variance',\n",
              "                                          threshold=0.6,\n",
              "                                          variables=['1stFlrSF', '2ndFlrSF',\n",
              "                                                     'BedroomAbvGr',\n",
              "                                                     'BsmtExposure',\n",
              "                                                     'BsmtFinSF1',\n",
              "                                                     'BsmtFinType1',\n",
              "                                                     'BsmtUnfSF', 'GarageArea',\n",
              "                                                     'GarageFinish',\n",
              "                                                     'GarageYrBlt', 'GrLivArea',\n",
              "                                                     'KitchenQual', 'LotArea',\n",
              "                                                     'LotFrontage',\n",
              "                                                     'MasVnrArea',\n",
              "                                                     'OpenPorchSF',\n",
              "                                                     'OverallCond',\n",
              "                                                     'OverallQual',\n",
              "                                                     'TotalBsmtSF', 'YearBuilt',\n",
              "                                                     'YearRemodAdd']))])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "### Data Cleaning\n",
        "from feature_engine.imputation import MeanMedianImputer\n",
        "from feature_engine.imputation import ArbitraryNumberImputer\n",
        "from feature_engine.imputation import CategoricalImputer\n",
        "\n",
        "### Feature Engineering\n",
        "from feature_engine.selection import SmartCorrelatedSelection\n",
        "from feature_engine.encoding import OrdinalEncoder\n",
        "from feature_engine import transformation as vt\n",
        "\n",
        "def PipelineDataCleaningAndFeatureEngineering():\n",
        "  pipeline_base = Pipeline([\n",
        "    (\"ArbitraryImputer\", ArbitraryNumberImputer(arbitrary_number=0,\n",
        "                                            variables=arbitrary_imputation_vars)),\n",
        "                                \n",
        "    (\"MedianImputation\", MeanMedianImputer(imputation_method='median',\n",
        "                                            variables=median_imputation_vars)),\n",
        "    \n",
        "    (\"CategoricalImputer\", CategoricalImputer(imputation_method='frequent', \n",
        "                                        variables=most_frequent_vars)),\n",
        "\n",
        "    (\"OrdinalCategoricalEncoder\",OrdinalEncoder(encoding_method='arbitrary', \n",
        "                                                variables = categorical_encoding_vars) ),\n",
        "    \n",
        "    (\"LogTransformer\", vt.YeoJohnsonTransformer(variables = yeojohnson_vars)),\n",
        "\n",
        "    (\"YeoJohnsonTransformer\", vt.YeoJohnsonTransformer(variables = yeojohnson_vars)),\n",
        "\n",
        "    (\"BoxCoxTransformer\", vt.BoxCoxTransformer(variables = boxcox_vars)),\n",
        "      \n",
        "    (\"SmartCorrelatedSelection\",SmartCorrelatedSelection(variables=smart_correlation_features, \n",
        "                                                          method=\"pearson\", threshold=0.6, \n",
        "                                                          selection_method=\"variance\") ),\n",
        "       \n",
        "  ])\n",
        "\n",
        "  return pipeline_base\n",
        "\n",
        "PipelineDataCleaningAndFeatureEngineering()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "# ML Pipeline for Modelling and Hyperparameter Optimization\n",
        "\n",
        "* Our next step is choosing the optimal algorithm for our ML model and the most effective hyperparameter for our selected algorithm\n",
        "* We will do so with the below function and custom class.\n",
        "    * Below code taken from CI lesson: *Scikit-Learn Unit 6: Cross Validation Search Part 2*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "### Feat Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "### Feat Selection\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "### ML algorithms \n",
        "from sklearn.linear_model import LogisticRegression \n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier \n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "def PipelineClf(model):\n",
        "  pipeline_base = Pipeline([\n",
        "       (\"scaler\",StandardScaler() ),\n",
        "       (\"feat_selection\",SelectFromModel(model) ),\n",
        "       (\"model\",model ),\n",
        "  ])\n",
        "\n",
        "  return pipeline_base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "class HyperparameterOptimizationSearch:\n",
        "\n",
        "    def __init__(self, models, params):\n",
        "        self.models = models\n",
        "        self.params = params\n",
        "        self.keys = models.keys()\n",
        "        self.grid_searches = {}\n",
        "\n",
        "    def fit(self, X, y, cv, n_jobs, verbose=1, scoring=None, refit=False):\n",
        "        for key in self.keys:\n",
        "            print(f\"\\nRunning GridSearchCV for {key} \\n\")\n",
        "\n",
        "            model =  PipelineClf(self.models[key])\n",
        "            params = self.params[key]\n",
        "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs, verbose=verbose, scoring=scoring, )\n",
        "            gs.fit(X,y)\n",
        "            self.grid_searches[key] = gs    \n",
        "\n",
        "    def score_summary(self, sort_by='mean_score'):\n",
        "        def row(key, scores, params):\n",
        "            d = {\n",
        "                 'estimator': key,\n",
        "                 'min_score': min(scores),\n",
        "                 'max_score': max(scores),\n",
        "                 'mean_score': np.mean(scores),\n",
        "                 'std_score': np.std(scores),\n",
        "            }\n",
        "            return pd.Series({**params,**d})\n",
        "\n",
        "        rows = []\n",
        "        for k in self.grid_searches:\n",
        "            params = self.grid_searches[k].cv_results_['params']\n",
        "            scores = []\n",
        "            for i in range(self.grid_searches[k].cv):\n",
        "                key = \"split{}_test_score\".format(i)\n",
        "                r = self.grid_searches[k].cv_results_[key]        \n",
        "                scores.append(r.reshape(len(params),1))\n",
        "\n",
        "            all_scores = np.hstack(scores)\n",
        "            for p, s in zip(params,all_scores):\n",
        "                rows.append((row(k, s, p)))\n",
        "\n",
        "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
        "        columns = ['estimator', 'min_score', 'mean_score', 'max_score', 'std_score']\n",
        "        columns = columns + [c for c in df.columns if c not in columns]\n",
        "        return df[columns], self.grid_searches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Split Train & Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1168, 21) (1168,) (292, 21) (292,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test,y_train, y_test = train_test_split(\n",
        "                                    df.drop(['SalePrice'],axis=1),\n",
        "                                    df['SalePrice'],\n",
        "                                    test_size = 0.2,\n",
        "                                    random_state = 0,\n",
        "                                    )\n",
        "\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "NOTE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* You may add how many sections you want, as long as it supports your project workflow.\n",
        "* All notebook's cells should be run top-down (you can't create a dynamic wherein a given point you need to go back to a previous cell to execute some task, like go back to a previous cell and refresh a variable content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Push files to Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* In case you don't need to push files to Repo, you may replace this section for \"Conclusions and Next Steps\" and state your conclusions and next steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKlnIozA4eQO",
        "outputId": "fd09bc1f-adb1-4511-f6ce-492a6af570c0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "try:\n",
        "  # create here your folder\n",
        "  # os.makedirs(name='')\n",
        "except Exception as e:\n",
        "  print(e)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
