{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Data Cleaning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* The purpose of this notebook is to:\n",
        "    * Evaluate the missing data levels\n",
        "    * Clean our dataset\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* outputs/datasets/collection/HousePriceRecords.csv\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* We will generate cleaned Train and Tests sets in this notebook and save to *outputs/datasets/cleaned*\n",
        "\n",
        "## CRISP-DM\n",
        "\n",
        "* Data Preperation \n",
        "\n",
        "## Conclusions\n",
        "\n",
        "* We will take the following actions:\n",
        "    * Arbitrary Imputation: '2ndFlrSF', 'EnclosedPorch', 'WoodDeckSF'\n",
        "    * Median Imputation: BedroomAbvGr', 'LotFrontage', 'GarageYrBlt', 'MasVnrArea'\n",
        "    * Most Frequent Imputation: 'BsmtFinType1', 'GarageFinish'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* The notebooks are stored in a sub folder, therefore when running the notebook in the editor, you will need to change the working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Load collected dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(f\"outputs/datasets/collection/HousePriceRecords.csv\")\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Data Exploration: Missing Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* First, we want to identify any variables with missing data\n",
        "    * Code taken from *CI Walkthrough Project: Churnometer; Data Cleaning*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vars_with_missing_data = df.columns[df.isna().sum() > 0].to_list()\n",
        "df.filter(vars_with_missing_data).info()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We want to inspect these variables more closely\n",
        "* We generate a profile report in order to check the shape and distribution of variables with missing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pandas_profiling import ProfileReport\n",
        "profile = ProfileReport(df=df[vars_with_missing_data], minimal=True)\n",
        "profile.to_notebook_iframe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Assessing Missing Data Levels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Custom function to display missing data levels in a dataframe, it shows the aboslute levels, relative levels and data type\n",
        "    * Taken from *Churnometer Data Cleaning notebook*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def EvaluateMissingData(df):\n",
        "    missing_data_absolute = df.isnull().sum()\n",
        "    missing_data_percentage = round(missing_data_absolute/len(df)*100, 2)\n",
        "    df_missing_data = (pd.DataFrame(\n",
        "                          data={\"RowsWithMissingData\": missing_data_absolute,\n",
        "                                \"PercentageOfDataset\": missing_data_percentage,\n",
        "                                \"DataType\": df.dtypes}\n",
        "                    )\n",
        "                    .sort_values(by=['PercentageOfDataset'], ascending=False)\n",
        "                    .query(\"PercentageOfDataset > 0\")\n",
        "                    )\n",
        "\n",
        "  return df_missing_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We check the missing levels of our dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "EvaluateMissingData(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dealing with our missing data\n",
        "\n",
        "* ### We have quite a few variables with missing data and varying levels of missing data across these variables. Therefore, we will be taking a few different approaches to handling the missing data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Arbitrary Number Imputation\n",
        "\n",
        "* 'EnclosedPorch', 'WoodDeckSF' & '2ndFlrSF' will be handled with an arbitrary Number Imputation of 0. Having studied the pandas Profile Report, I present the rationale below:\n",
        "\n",
        "    1. 5.9% of the rows are missing data for '2ndFlrSF'. This is not a particularly high amount. The median value of the rows with non-missing rows is 0 and this value represents 53% of the entire variable in this dataset. A value of 0 seems to indicate that the property has no second floor. Missing values may also mean there is no second floor and as the missing level is relativley low, we will arbitrarily impute 0.\n",
        "    2. 'EnclosedPorch' & 'WoodDeckSF' have very high levels of missing data, 90.7% & 89.4% respectively. Similarly in these cases, missing data may indicate that there is no Porch or no Wood Deck on the property. Considering solely non-missing data, 79% of 'EnclosedPorch' has a value of 0 and over 50% of 'WoodDeckSF' has a value of 0. The indication is that a high number of properties have neither of these features and so we could arbitrarily impute 0.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "arbitrary_imputation_vars = ['2ndFlrSF', 'EnclosedPorch', 'WoodDeckSF']\n",
        "arbitrary_imputation_vars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from feature_engine.imputation import ArbitraryNumberImputer\n",
        "arbitrary_imputer = ArbitraryNumberImputer(arbitrary_number=0,\n",
        "                                           variables=arbitrary_imputation_vars)\n",
        "df_cleaned = df.copy()\n",
        "df_cleaned = arbitrary_imputer.fit_transform(df_cleaned)\n",
        "df_cleaned.filter(arbitrary_imputation_vars).info()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Median Imputation\n",
        "\n",
        "* 'BedroomAbvGr', 'LotFrontage' & 'MasVnrArea' will be handled with a median imputation method. Having studied the pandas Profile Report, I will present the rationales below:\n",
        "\n",
        "    1. 'MasVnrArea' has only 8 missing rows and the median value, 0, accounts for almost 69% of this variable. It appears safe to impute the median value for the 8 missing rows of data.\n",
        "\n",
        "    2. 'BedroomAbvGr' also has a relatively low level of missing rows (6.8%). This variables histogram has quite a normal distribution, so a mean imputation may be advisable but the mean and median are both 3 when the mean is rounded to the nearest whole number, so we use median imputation with the other variables.\n",
        "\n",
        "    3. 'GarageYrBlt' has a relatively low level of missing rows (5.5%). We notice that exactly 5.5% of values for 'GarageArea' equal zero. This suggests that missing 'GarageYrBlt' values correspond to properties with no garage. Some of these properties will have been built after 1980 and therefore in real world terms, imputing the median which is 1980 does not make sense. However, if these properties do not have garages, then there is no point in arbitrarily imputing a different false value, so we choose median imputation.\n",
        "    \n",
        "    3. 'LotFrontage' has a higher level of missing values (17.7%). There are no zero values however which seems to rule out a missing value possibly equalling 0. Judging from the histogram and skew levels, this variable is quite skewed so median imputation seems the best option in this case."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "median_imputation_vars = ['BedroomAbvGr', 'LotFrontage', 'GarageYrBlt',\n",
        "                          'MasVnrArea']\n",
        "median_imputation_vars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from feature_engine.imputation import MeanMedianImputer\n",
        "median_imputer = MeanMedianImputer(imputation_method='median',\n",
        "                                   variables=median_imputation_vars)\n",
        "df_cleaned = median_imputer.fit_transform(df_cleaned)\n",
        "df_cleaned.filter(median_imputation_vars).info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Impute Most Frequest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We have two categorical variables, 'BsmtFinType1' & 'GarageFinish', with missing data. Our imputation method to handle this missing data will be to replace the missing values with the most frequent value in these columns. \n",
        "\n",
        "* We will use CategoricalImputer. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "categorical_imputation_vars = ['BsmtFinType1', 'GarageFinish']\n",
        "categorical_imputation_vars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from feature_engine.imputation import CategoricalImputer\n",
        "categorical_imputer = CategoricalImputer(imputation_method='frequent',\n",
        "                                         variables=categorical_imputation_vars)\n",
        "df_cleaned = categorical_imputer.fit_transform(df_cleaned)\n",
        "df_cleaned.filter(categorical_imputation_vars).info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Sidenote:\n",
        "* For 'GarageFinish', a custom approach was considered under the following rationale:\n",
        "    * *It was suggested above that if 'GarageArea' is equal to 0, that the property represented by that row does not have a garage. Therefore, if a row contains missing data for 'GarageFinish', but also 'GarageArea' is equal to 0, we will replace the misssing value with 'None'. Otherwise, we will replace it with the most frequent value which is 'Unf'.*\n",
        "* The below approach was tested:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We gathered which index values correspond to rows with missing values for 'GarageFinish' and add them to a list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "nan_GarageFinish_vals = df[df['GarageFinish'].isna()]\n",
        "nan_GarageFinish_index = list(nan_GarageFinish_vals.index.values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We converted missing values to 0, in order to replace them with our preferred values.\n",
        "* We declared garage_area_value as the value for 'GarageArea' for any given row and iterate through our list of index values.\n",
        "* If there is no garage, 'GarageArea' is equal to zero, we set 'GarageFinish' to 'None', otherwise we set it to 'Unf', the most frequent value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_aside = df_cleaned.copy()\n",
        "df_aside['GarageFinish'] = df_aside['GarageFinish'].fillna(0)\n",
        "\n",
        "for x in nan_GarageFinish_index:\n",
        "    garage_area_value = df.iloc[x, 8]\n",
        "    if garage_area_value == 0:\n",
        "        df_aside.at[x, 'GarageFinish'] = 'None'\n",
        "    else:\n",
        "        df_aside.at[x, 'GarageFinish'] = 'Unf'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We checked that there are no missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_aside.filter(['GarageFinish']).value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We will assess the missing Data levels on our cleaned Dataframe\n",
        "    * Custome function DataCleaningEffect taken from *Feature Engine Unit 9: Custom Functions*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "EvaluateMissingData(df_aside)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* A customer imputer was considered but during testing of 'v1' pipeline, it was found that simply imputing the most frequent variable was more effective in predictions than the 'more realistic' custom approach, so we are progressing with the 'most frequent' approach."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Assessing effect of Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "sns.set(style=\"whitegrid\")\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "def DataCleaningEffect(df_original, df_cleaned, variables_applied_with_method):\n",
        "\n",
        "    flag_count = 1  # Indicate plot number\n",
        "\n",
        "    # distinguish between numerical and categorical variables\n",
        "    categorical_variables = (df_original.select_dtypes(exclude=['number'])\n",
        "                             .columns)\n",
        "\n",
        "    # scan over variables,\n",
        "    # first on variables that you applied the method\n",
        "    # if the variable is a numerical plot, a histogram if\n",
        "    # categorical plot a barplot\n",
        "    for set_of_variables in [variables_applied_with_method]:\n",
        "        print(\"\\n===========================================================\" +\n",
        "              \"==========================\")\n",
        "        print(f\"* Distribution Effect Analysis After Data Cleaning Method in\" +\n",
        "              \" the following variables:\")\n",
        "        print(f\"{set_of_variables} \\n\\n\")\n",
        "\n",
        "    for var in set_of_variables:\n",
        "        if var in categorical_variables:  # it is categorical variable: barplot\n",
        "\n",
        "            df1 = pd.DataFrame({\"Type\": \"Original\", \"Value\": df_original[var]})\n",
        "            df2 = pd.DataFrame({\"Type\": \"Cleaned\", \"Value\": df_cleaned[var]})\n",
        "            dfAux = pd.concat([df1, df2], axis=0)\n",
        "            fig, axes = plt.subplots(figsize=(15, 5))\n",
        "            sns.countplot(hue='Type', data=dfAux, x=\"Value\",\n",
        "                          palette=['#432371', \"#FAAE7B\"])\n",
        "            axes.set(title=f\"Distribution Plot {flag_count}: {var}\")\n",
        "            plt.xticks(rotation=90)\n",
        "            plt.legend()\n",
        "\n",
        "        else:  # it is numerical variable: histogram\n",
        "\n",
        "            fig, axes = plt.subplots(figsize=(10, 5))\n",
        "            sns.histplot(data=df_original, x=var, color=\"#432371\",\n",
        "                         label='Original', kde=True, element=\"step\", ax=axes)\n",
        "            sns.histplot(data=df_cleaned, x=var, color=\"#FAAE7B\",\n",
        "                         label='Cleaned', kde=True, element=\"step\", ax=axes)\n",
        "            axes.set(title=f\"Distribution Plot {flag_count}: {var}\")\n",
        "            plt.legend()\n",
        "\n",
        "    plt.show()\n",
        "    flag_count += 1\n",
        "\n",
        "\n",
        "DataCleaningEffect(df, df_cleaned, vars_with_missing_data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* There is a big change in the distribution of 'EnclosedPorch' & 'WoodDeckSF'. The missing levels of these variables was very large to begin with so it could be argues that dropping them was valid. However, our rationale for imputing zero makes real world sense so we will keep thme in our cleaned dataset for now."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Split Train and Test Set\n",
        "\n",
        "* We will now split our cleaned data into our train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "TrainSet, TestSet, _, __ = train_test_split(\n",
        "                                        df_cleaned,\n",
        "                                        df_cleaned['SalePrice'],\n",
        "                                        test_size=0.2,\n",
        "                                        random_state=0)\n",
        "\n",
        "print(f\"TrainSet shape: {TrainSet.shape} \\nTestSet shape: {TestSet.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We ensure there is no missing data before we push our cleaned data to the repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "EvaluateMissingData(TrainSet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "EvaluateMissingData(TestSet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Push cleaned files to Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* In case you don't need to push files to Repo, you may replace this section for \"Conclusions and Next Steps\" and state your conclusions and next steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKlnIozA4eQO",
        "outputId": "fd09bc1f-adb1-4511-f6ce-492a6af570c0"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    # Creates cleaned folder\n",
        "    os.makedirs(name='outputs/datasets/cleaned')\n",
        "except Exception as e:\n",
        "    print(e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "TrainSet.to_csv(\"outputs/datasets/cleaned/TrainSetCleaned.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "TestSet.to_csv(\"outputs/datasets/cleaned/TestSetCleaned.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12 (default, Oct 14 2022, 17:27:18) \n[GCC 9.4.0]"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
